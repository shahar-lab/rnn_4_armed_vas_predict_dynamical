{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67e92ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d88b2d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU_RNN_TWO(nn.Module):\n",
    "        \n",
    "    def __init__(self,input_size, hidden_size, num_of_layers, num_alpha_embedding, num_beta_embedding, output_size, dropout):\n",
    "        \n",
    "        super(GRU_RNN_TWO, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.num_alpha_embedding = num_alpha_embedding\n",
    "        self.num_beta_embedding = num_beta_embedding        \n",
    "        \n",
    "        self.hidden_0 = nn.GRU(  \n",
    "                    input_size=input_size,\n",
    "                    hidden_size=hidden_size,\n",
    "                    num_layers=num_of_layers,\n",
    "                    batch_first=True,\n",
    "                    dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.hidden_1 = nn.GRU(  \n",
    "                    input_size=input_size + num_alpha_embedding + num_beta_embedding,\n",
    "                    hidden_size=hidden_size,\n",
    "                    num_layers=num_of_layers,\n",
    "                    batch_first=True,\n",
    "                    dropout=dropout \n",
    "        )\n",
    "    \n",
    "        \n",
    "        self.out_alpha = nn.Linear(hidden_size, num_alpha_embedding)\n",
    "        self.out_beta = nn.Linear(hidden_size, num_beta_embedding)\n",
    "        \n",
    "        self.relu_alpha = nn.ReLU()\n",
    "        self.relu_beta = nn.ReLU()\n",
    "\n",
    "        self.reg_alpha = nn.Linear(num_alpha_embedding, 1)\n",
    "        self.reg_beta = nn.Linear(num_beta_embedding, 1)\n",
    "\n",
    "        \n",
    "        self.out_action = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # parameters estimation\n",
    "        output_0, hn_0 = self.hidden_0(x)\n",
    "        \n",
    "        output_alpha = self.out_alpha(output_0)\n",
    "        output_alpha = self.relu_alpha(output_alpha)\n",
    "        \n",
    "        output_beta = self.out_beta(output_0)\n",
    "        output_beta = self.relu_beta(output_beta)\n",
    "        \n",
    "        cont_output_alpha = self.reg_alpha(output_alpha)\n",
    "        cont_output_beta = self.reg_beta(output_beta)\n",
    "    \n",
    "        # concat input \n",
    "        input_1 = torch.concat([x[0],output_alpha[0],output_beta[0]],dim=1) # cat\n",
    "        input_1 = input_1.reshape(1,x.shape[1],self.input_size + self.num_alpha_embedding\n",
    "                                  + self.num_beta_embedding)\n",
    "        \n",
    "        # action predication\n",
    "        output_action, hn_1 = self.hidden_1(input_1)\n",
    "        output_action = self.out_action(output_action)\n",
    "        output_action = F.softmax(output_action,dim=-1)\n",
    "        \n",
    "        output_dis = [output_alpha, output_beta]\n",
    "        output_cont = [cont_output_alpha, cont_output_beta]\n",
    "\n",
    "        return output_dis, output_cont, output_action, hn_0, hn_1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fddd7077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 5)%3\n",
    "F.one_hot(torch.arange(0, 1) , num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccca69bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class behavior_dataset(Dataset):\n",
    "    \"\"\"         \n",
    "    \"\"\"\n",
    "    def __init__(self,dataframe):\n",
    "        \n",
    "        # action one hot transformation \n",
    "        action = np.array(dataframe['action'])\n",
    "        if np.all(action == action[0]):\n",
    "            action = np.append(action,(1-action[0]))\n",
    "            action = torch.tensor((action).reshape(len(dataframe) + 1),dtype=int)\n",
    "            action_onehot = nn.functional.one_hot(action, len(action.unique()))\n",
    "            # delete last one\n",
    "            action_onehot = action_onehot[:-1]\n",
    "        else:\n",
    "            action = torch.tensor((action).reshape(len(dataframe)),dtype=int)\n",
    "            action_onehot = nn.functional.one_hot(action, len(action.unique()))\n",
    "        \n",
    "        # reward\n",
    "        reward = torch.tensor((np.array(dataframe['reward'])).reshape(len(dataframe)),dtype=int)\n",
    "        \n",
    "        # state one hot transformation\n",
    "        state = np.array(dataframe['state'])\n",
    "        state_shift = np.insert(state,-1,0)[1:]\n",
    "        state_shift = torch.tensor((state_shift).reshape(len(dataframe)),dtype=int)\n",
    "        state_onehot = nn.functional.one_hot(state_shift, 12)\n",
    "\n",
    "\n",
    "        # concatinating reward and action\n",
    "        reward_action_state = torch.cat([reward[ :, np.newaxis], action_onehot, state_onehot],1)\n",
    "        \n",
    "        # adding dummy zeros to the beginning and ignoring the last one\n",
    "        reward_action_state_shift = nn.functional.pad(reward_action_state,[0,0,1,0])[:-1]\n",
    "        \n",
    "        # make the first trial in every block to zeros\n",
    "        n_blocks = int(len(dataframe)/25) \n",
    "        reward_action_state_shift.reshape(n_blocks,25,INPUT_SIZE)[:,0,:] = torch.zeros(size=(n_blocks,INPUT_SIZE))\n",
    "\n",
    "        # parameters one hot transformation \n",
    "        dis_alpha = torch.tensor((np.array(dataframe['alpha_categorical'])).reshape(len(dataframe)),dtype=int)\n",
    "        dis_alpha = dis_alpha.type(dtype=torch.float32)\n",
    "        \n",
    "        # parameters one hot transformation \n",
    "        dis_beta = torch.tensor((np.array(dataframe['beta_categorical'])).reshape(len(dataframe)),dtype=int)\n",
    "        dis_beta = dis_beta.type(dtype=torch.float32)\n",
    "\n",
    "        cont_alpha = torch.tensor((np.array(dataframe['alpha'])).reshape(len(dataframe)),dtype=torch.float32)\n",
    "        cont_beta = torch.tensor((np.array(dataframe['beta'])).reshape(len(dataframe)),dtype=torch.float32)\n",
    "        \n",
    "        # network input \n",
    "        x = reward_action_state_shift\n",
    "\n",
    "        # network output \n",
    "        y = torch.cat([action_onehot, dis_alpha[ :, np.newaxis],  dis_beta[ :, np.newaxis], \n",
    "                                      cont_alpha[ :, np.newaxis], cont_beta[ :, np.newaxis]\n",
    "                      ],1)\n",
    "  \n",
    "        self.x = x.type(dtype=torch.float32)\n",
    "        self.y = y.type(dtype=torch.float32)\n",
    "        self.len = len(dataframe)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len    \n",
    "    \n",
    "class merge_behavior_dataset(Dataset):\n",
    "    \"\"\" \n",
    "    Merge Dataset of each agent to one dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset_list: list of Dataset of all agent \n",
    "        n_trials: num_of_trials each agent was simulated\n",
    "        \n",
    "    Returns: \n",
    "        torch Dataset:\n",
    "        x: [reward_(t-1) , action_(t-1), state_(t-1)] all agents\n",
    "        y: [action_t, parameter embedding] all agents\n",
    "        \n",
    "    \"\"\"\n",
    "    def __init__(self, dataset_list, n_trials):\n",
    "        X = []\n",
    "        Y = []\n",
    "        for agent in dataset_list:\n",
    "            for i in range(n_trials):\n",
    "                X.append(agent[i][0])\n",
    "                Y.append(agent[i][1])\n",
    "                \n",
    "        self.x = torch.stack(X).type(dtype=torch.float32)\n",
    "        self.y = torch.stack(Y).type(dtype=torch.float32)\n",
    "        self.len = len(X)   \n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        return self.x[idx],self.y[idx]\n",
    "  \n",
    "    def __len__(self):\n",
    "        return self.len    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2ebbb110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_two(net, train_loader, val_loader ,epochs, name):\n",
    "        \n",
    "    min_loss_t = 100\n",
    "    min_loss_v = 100\n",
    "        \n",
    "    # array to track loss \n",
    "    train_loss_array , val_loss_array = [], []\n",
    "    \n",
    "    # move net to GPU\n",
    "    net.to(device)\n",
    "\n",
    "    # Use Adam optimizer\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.001) \n",
    "    \n",
    "    # start timer\n",
    "    start_time = time.time()   \n",
    "    \n",
    "    # Loop over epochs \n",
    "    for i in range(epochs):        \n",
    "        # Randomize train batch example \n",
    "        train_loader = random.sample(list(train_loader), len(train_loader))\n",
    "      \n",
    "        running_loss = 0\n",
    "        \n",
    "        run_action, run_d_alpha ,run_d_beta = 0,0,0\n",
    "        run_c_alpha, run_c_beta  = 0,0 \n",
    "        # Loop over training batches\n",
    "        for j, (X, y_true) in enumerate(train_loader):\n",
    "    \n",
    "            X, y_true = X.to(device), y_true.to(device) # move to GPU\n",
    "            X = X.reshape(1,X.shape[0],INPUT_SIZE) # reshape to  1 x trials x input_size\n",
    "            \n",
    "            optimizer.zero_grad()  # zero the gradient buffers\n",
    "            \n",
    "            y_hat_dis, y_hat_cont, y_hat_action, _, _  = net(X) # forward pass\n",
    "            \n",
    "            y_hat_action = (y_hat_action.view(-1, num_of_action)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_dis_alpha = (y_hat_dis[0].view(-1, num_alpha_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_dis_beta = (y_hat_dis[1].view(-1, num_beta_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "\n",
    "            \n",
    "            y_hat_dis = [y_hat_dis_alpha,y_hat_dis_beta]\n",
    " \n",
    "            y_hat_cont_alpha = (y_hat_cont[0].view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_cont_beta = (y_hat_cont[1].view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "\n",
    "            \n",
    "            y_hat_cont = [y_hat_cont_alpha,y_hat_cont_beta]\n",
    "\n",
    "            loss, l_action, l_dis, l_cont = multi_loss(y_hat_action, y_hat_dis, y_hat_cont, y_true) # compute loss\n",
    "                                                                                           \n",
    "\n",
    "            loss.backward() # backprop the loss\n",
    "            optimizer.step() # update the weights \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            run_action += l_action.item()\n",
    "        \n",
    "            run_d_alpha += l_dis[0].item()\n",
    "            run_d_beta += l_dis[1].item()\n",
    "\n",
    "            \n",
    "            run_c_alpha += l_cont[0].item()\n",
    "            run_c_beta += l_cont[1].item()\n",
    "\n",
    "            \n",
    "        train_loss_array.append(running_loss/len(train_loader))\n",
    "        loss = eval_net_two(net,val_loader)\n",
    "        val_loss_array.append(loss)\n",
    "        \n",
    "        print('================')\n",
    "        print('loss BCE action',(run_action/len(train_loader)))\n",
    "        \n",
    "        print('================')\n",
    "        print('loss CE alpha',(run_d_alpha/len(train_loader)))\n",
    "        print('loss CE beta',(run_d_beta/len(train_loader)))\n",
    "\n",
    "        \n",
    "        print('================')\n",
    "        print('loss mse alpha',(run_c_alpha/len(train_loader)))\n",
    "        print('loss mse beta',(run_c_beta/len(train_loader)))\n",
    "    \n",
    "        \n",
    "        if train_loss_array[i] <= min_loss_t:\n",
    "            checkpoint = {'epoch':i+1,'model_state':net.state_dict(),\n",
    "                          'optim_state':optimizer.state_dict(),'loss':train_loss_array[i]}\n",
    "            torch.save(checkpoint,f'checkpoint_best_train_{name}.pth')\n",
    "\n",
    "            min_loss_t = train_loss_array[i]\n",
    "\n",
    "        if val_loss_array[i] <= min_loss_v:\n",
    "            checkpoint = {'epoch':i+1,'model_state':net.state_dict(),\n",
    "                          'optim_state':optimizer.state_dict(),'loss':val_loss_array[i]}\n",
    "            torch.save(checkpoint,f'checkpoint_best_val_{name}.pth')\n",
    "\n",
    "            min_loss_v = val_loss_array[i]\n",
    "\n",
    "        print('Step {}, Train Loss {:0.4f}, Val Loss {:0.4f}, Time {:0.1f}s'.format(i+1,\n",
    "                                                                                    train_loss_array[i],\n",
    "                                                                                    val_loss_array[i],\n",
    "                                                                                    time.time() - start_time))\n",
    "\n",
    "        net.train()\n",
    "\n",
    "            \n",
    "    return net, train_loss_array , val_loss_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c0bae570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  2  8  3 10  2  8  3  7  9  7  5 10  2  7 11  2  8  9  3  9 11\n",
      "  5 11  9  3  1  5  9  8  7  7  1  3 10  6 10 11  6 10  3  4  8 10  4  8\n",
      "  8  9  1  1  5  3  8  1  8  8  9  8  4  5 11  8  7  2  7  2  0  9  9  7\n",
      " 11  8  1  9  4  0  9  4  8 10 10  7  0  0  2  4  9  7  8  2  4 11 11  5\n",
      "  4  0  5  3  6  8  1 10  5 10  4  7  3  3 11 11  1  5 10 10  4  2  7  2\n",
      "  6  3 11  5  9  3  5  0 11  2  0  9  9  4  1  9 11  2 10 11 11  3  7  9\n",
      "  6  7  7  8  8  2  8  7  3 11  1  0  4 11  8  6  8  9  3  4  8 10  3 11\n",
      "  4  0  2 10  4  3  6  8  5 11  3  5  3  1  7  3 10  4  4  7  7  0 11  1\n",
      "  7 10  2  6  9  1 10  7]\n",
      "200\n",
      "[ 1  1  2  8  3 10  2  8  3  7  9  7  5 10  2  7 11  2  8  9  3  9 11  5\n",
      " 11  9  3  1  5  9  8  7  7  1  3 10  6 10 11  6 10  3  4  8 10  4  8  8\n",
      "  9  1  1  5  3  8  1  8  8  9  8  4  5 11  8  7  2  7  2  0  9  9  7 11\n",
      "  8  1  9  4  0  9  4  8 10 10  7  0  0  2  4  9  7  8  2  4 11 11  5  4\n",
      "  0  5  3  6  8  1 10  5 10  4  7  3  3 11 11  1  5 10 10  4  2  7  2  6\n",
      "  3 11  5  9  3  5  0 11  2  0  9  9  4  1  9 11  2 10 11 11  3  7  9  6\n",
      "  7  7  8  8  2  8  7  3 11  1  0  4 11  8  6  8  9  3  4  8 10  3 11  4\n",
      "  0  2 10  4  3  6  8  5 11  3  5  3  1  7  3 10  4  4  7  7  0 11  1  7\n",
      " 10  2  6  9  1 10  0  7]\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "path = f'../data/artificial_trainset_2000_non_stat.csv'\n",
    "df = pd.read_csv(path)\n",
    "s = 0\n",
    "e = 200\n",
    "cur_df = df.iloc[s:e]\n",
    "cur_df = cur_df.reset_index()\n",
    "state = np.array(cur_df['state'])\n",
    "print(state)\n",
    "print(len(state))\n",
    "new_state = np.insert(state,-1,0)[1:]\n",
    "print(new_state)\n",
    "print(len(new_state))\n",
    "#state = torch.tensor((state).reshape(len(dataframe)),dtype=int)\n",
    "#state_onehot = nn.functional.one_hot(state, 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bf1b9c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net_two(net, val_loader):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        running_loss = 0\n",
    "        for j, (X, y_true) in enumerate(val_loader):\n",
    "            \n",
    "            X, y_true = X.to(device), y_true.to(device) # move to GPU\n",
    "            X = X.reshape(1,X.shape[0],INPUT_SIZE) # reshape to  1 x trials x input_size\n",
    "            \n",
    "            y_hat_dis, y_hat_cont, y_hat_action, _, _  = net(X) # forward pass\n",
    "            \n",
    "            y_hat_action = (y_hat_action.view(-1, num_of_action)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_dis_alpha = (y_hat_dis[0].view(-1, num_alpha_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_dis_beta = (y_hat_dis[1].view(-1, num_beta_embedding)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "\n",
    "            \n",
    "            y_hat_dis = [y_hat_dis_alpha,y_hat_dis_beta]\n",
    " \n",
    "            y_hat_cont_alpha = (y_hat_cont[0].view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "            y_hat_cont_beta = (y_hat_cont[1].view(-1)) # Reshape to (SeqLen x Batch, OutputSize)\n",
    "\n",
    "            \n",
    "            y_hat_cont = [y_hat_cont_alpha,y_hat_cont_beta]\n",
    "\n",
    "            loss, l_action, l_dis, l_cont = multi_loss(y_hat_action, y_hat_dis, y_hat_cont, y_true) # compute loss\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    return (running_loss/len(val_loader))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc7121a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_of_trials: 200\n",
      "num_of_agents: 2000\n",
      "num_alpha_embedding: 5\n",
      "num_beta_embedding: 5\n",
      "train_size: 320000\n",
      "train_size: torch.Size([320000, 15])\n",
      "val_size: 80000\n",
      "val_size: torch.Size([80000, 15])\n"
     ]
    }
   ],
   "source": [
    "path = f'../data/artificial_trainset_2000_non_stat.csv'\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# define constant \n",
    "num_of_action = df['action'].nunique()\n",
    "num_of_trials = df['trial'].nunique()\n",
    "num_of_agents = df['agent'].nunique()\n",
    "num_alpha_embedding = df['alpha_categorical'].nunique()\n",
    "num_beta_embedding = df['beta_categorical'].nunique()\n",
    "\n",
    "# netowrk input and output dimension  \n",
    "INPUT_SIZE = 1 + num_of_action + 12\n",
    "OUTPUT_SIZE = num_of_action\n",
    "\n",
    "# train val test split \n",
    "n_agent_train = int(0.8*num_of_agents)\n",
    "n_agent_val = int(0.2*num_of_agents)\n",
    "\n",
    "all_data = []\n",
    "for i in range(num_of_agents):\n",
    "    s = i*num_of_trials\n",
    "    e = (i+1)*num_of_trials\n",
    "    cur_df = df.iloc[s:e]\n",
    "    cur_df = cur_df.reset_index()\n",
    "    all_data.append([i,behavior_dataset(cur_df)])\n",
    "    \n",
    "random.shuffle(all_data)\n",
    "all_data = np.array(all_data)\n",
    "train_dataset = all_data[:n_agent_train,1]\n",
    "train_dataset = merge_behavior_dataset(train_dataset,num_of_trials)\n",
    "\n",
    "val_dataset = all_data[n_agent_train:,1]\n",
    "val_dataset = merge_behavior_dataset(val_dataset,num_of_trials)\n",
    "val_agents = np.array([all_data[i,0] for i in range(n_agent_train,num_of_agents)])\n",
    "    \n",
    "print('num_of_trials:',num_of_trials)\n",
    "print('num_of_agents:',num_of_agents)\n",
    "print('num_alpha_embedding:',num_alpha_embedding)\n",
    "print('num_beta_embedding:',num_beta_embedding)\n",
    "print('train_size:', n_agent_train*num_of_trials)\n",
    "print('train_size:', train_dataset[:][0].shape)\n",
    "print('val_size:', n_agent_val*num_of_trials)\n",
    "print('val_size:', val_dataset[:][0].shape)\n",
    "# print('val_agents',val_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d803d7de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agent</th>\n",
       "      <th>block</th>\n",
       "      <th>trial</th>\n",
       "      <th>card_0</th>\n",
       "      <th>card_1</th>\n",
       "      <th>action</th>\n",
       "      <th>reward</th>\n",
       "      <th>state</th>\n",
       "      <th>state_onehot</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>alpha_categorical</th>\n",
       "      <th>beta_categorical</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]</td>\n",
       "      <td>0.569060</td>\n",
       "      <td>3.711152</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]</td>\n",
       "      <td>0.569060</td>\n",
       "      <td>3.711152</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]</td>\n",
       "      <td>0.569060</td>\n",
       "      <td>3.711152</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]</td>\n",
       "      <td>0.569060</td>\n",
       "      <td>3.711152</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]</td>\n",
       "      <td>0.569060</td>\n",
       "      <td>3.711152</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399995</th>\n",
       "      <td>1999</td>\n",
       "      <td>7</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]</td>\n",
       "      <td>0.921076</td>\n",
       "      <td>2.638504</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399996</th>\n",
       "      <td>1999</td>\n",
       "      <td>7</td>\n",
       "      <td>196</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]</td>\n",
       "      <td>0.921076</td>\n",
       "      <td>2.638504</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399997</th>\n",
       "      <td>1999</td>\n",
       "      <td>7</td>\n",
       "      <td>197</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]</td>\n",
       "      <td>0.921076</td>\n",
       "      <td>2.638504</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399998</th>\n",
       "      <td>1999</td>\n",
       "      <td>7</td>\n",
       "      <td>198</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]</td>\n",
       "      <td>0.921076</td>\n",
       "      <td>2.638504</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399999</th>\n",
       "      <td>1999</td>\n",
       "      <td>7</td>\n",
       "      <td>199</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]</td>\n",
       "      <td>0.921076</td>\n",
       "      <td>2.638504</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        agent  block  trial  card_0  card_1  action  reward  state  \\\n",
       "0           0      0      0       1       0       1       0      3   \n",
       "1           0      0      1       2       1       1       1      7   \n",
       "2           0      0      2       1       0       0       1      3   \n",
       "3           0      0      3       3       2       0       1     11   \n",
       "4           0      0      4       2       1       1       0      7   \n",
       "...       ...    ...    ...     ...     ...     ...     ...    ...   \n",
       "399995   1999      7    195       0       3       1       0      2   \n",
       "399996   1999      7    196       2       1       0       1      7   \n",
       "399997   1999      7    197       3       1       0       1     10   \n",
       "399998   1999      7    198       2       0       1       1      6   \n",
       "399999   1999      7    199       2       1       0       0      7   \n",
       "\n",
       "                                 state_onehot     alpha      beta  \\\n",
       "0       [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]  0.569060  3.711152   \n",
       "1       [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]  0.569060  3.711152   \n",
       "2       [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]  0.569060  3.711152   \n",
       "3       [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]  0.569060  3.711152   \n",
       "4       [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]  0.569060  3.711152   \n",
       "...                                       ...       ...       ...   \n",
       "399995  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]  0.921076  2.638504   \n",
       "399996  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]  0.921076  2.638504   \n",
       "399997  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]  0.921076  2.638504   \n",
       "399998  [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]  0.921076  2.638504   \n",
       "399999  [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]  0.921076  2.638504   \n",
       "\n",
       "        alpha_categorical  beta_categorical  \n",
       "0                       2                 1  \n",
       "1                       2                 1  \n",
       "2                       2                 1  \n",
       "3                       2                 1  \n",
       "4                       2                 1  \n",
       "...                   ...               ...  \n",
       "399995                  4                 1  \n",
       "399996                  4                 1  \n",
       "399997                  4                 1  \n",
       "399998                  4                 1  \n",
       "399999                  4                 1  \n",
       "\n",
       "[400000 rows x 13 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f901a6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_dataset[:][0][1]\n",
    "train_dataset[:][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3041c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_loss(y_hat_action, y_hat_dis, y_hat_cont, y_true):\n",
    "    \n",
    "    # slice true action and true parameters embedding \n",
    "    y_true_action = y_true[:,:2]\n",
    "    \n",
    "    y_true_dis_alpha = torch.flatten(y_true[:,2])\n",
    "    y_true_dis_alpha = y_true_dis_alpha.type(dtype=torch.LongTensor).to(device)\n",
    "    \n",
    "    y_true_dis_beta = torch.flatten(y_true[:,3])\n",
    "    y_true_dis_beta = y_true_dis_beta.type(dtype=torch.LongTensor).to(device)\n",
    "    \n",
    "    y_true_cont_alpha =  y_true[:,4]\n",
    "    y_true_cont_beta =  y_true[:,5]\n",
    "    \n",
    "    # define losses\n",
    "    criterion0 = nn.BCELoss()\n",
    "    criterion1 = nn.CrossEntropyLoss()\n",
    "    criterion2 = nn.MSELoss()\n",
    "    \n",
    "    l_action = criterion0(y_hat_action, y_true_action)\n",
    "    \n",
    "    l_dis_alpha = criterion1(y_hat_dis[0], y_true_dis_alpha)\n",
    "    l_dis_beta = criterion1(y_hat_dis[1], y_true_dis_beta)\n",
    "    \n",
    "    l_cont_alpha = criterion2(y_hat_cont[0],y_true_cont_alpha)\n",
    "    l_cont_beta = criterion2(y_hat_cont[1],y_true_cont_beta)\n",
    "    \n",
    "    # combine losses\n",
    "    #total_loss = 1*l_action + 0.2*l_dis_alpha  +  0.2*l_dis_beta  + 6*l_cont_alpha  + 0.1*l_cont_beta \n",
    "    #total_loss = 1*l_action + 0.4*l_dis_alpha  +  0.5*l_dis_beta  + 6*l_cont_alpha  + 0.1*l_cont_beta  #7\n",
    "    #total_loss = 1*l_action + 0.4*l_dis_alpha  +  0.45*l_dis_beta  + 6.5*l_cont_alpha  + 0.1*l_cont_beta  #8\n",
    "    total_loss = 1*l_action + 0.35*l_dis_alpha  +  0.45*l_dis_beta  + 7*l_cont_alpha  + 0.1*l_cont_beta  #9\n",
    "                \n",
    "    return total_loss, 1*l_action, [0.35*l_dis_alpha,  0.45*l_dis_beta ], [7*l_cont_alpha, 0.1*l_cont_beta] \n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a2cc2dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([1.0000, 0.0000, 1.0000, 0.0000, 0.3476, 1.4063]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "43bab64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "loss BCE action 0.6780169371515512\n",
      "================\n",
      "loss CE alpha 0.5807486806996167\n",
      "loss CE beta 0.9794085747562349\n",
      "================\n",
      "loss mse alpha 0.7428621260449291\n",
      "loss mse beta 1.5723085119388998\n",
      "Step 1, Train Loss 4.5533, Val Loss 3.7993, Time 18.7s\n",
      "================\n",
      "loss BCE action 0.6739369327202439\n",
      "================\n",
      "loss CE alpha 0.57486053686589\n",
      "loss CE beta 1.0207731917500495\n",
      "================\n",
      "loss mse alpha 0.5867173779988661\n",
      "loss mse beta 0.847118693497032\n",
      "Step 2, Train Loss 3.7034, Val Loss 3.7078, Time 35.7s\n",
      "================\n",
      "loss BCE action 0.6732162581756711\n",
      "================\n",
      "loss CE alpha 0.5746967158280313\n",
      "loss CE beta 0.9650489155203104\n",
      "================\n",
      "loss mse alpha 0.586731931567192\n",
      "loss mse beta 0.8416957295034081\n",
      "Step 3, Train Loss 3.6414, Val Loss 3.6637, Time 54.4s\n",
      "================\n",
      "loss BCE action 0.669904931075871\n",
      "================\n",
      "loss CE alpha 0.5739821156486868\n",
      "loss CE beta 0.9309854963794351\n",
      "================\n",
      "loss mse alpha 0.5810561483260244\n",
      "loss mse beta 0.8371499628759921\n",
      "Step 4, Train Loss 3.5931, Val Loss 3.6192, Time 75.0s\n",
      "================\n",
      "loss BCE action 0.6635437130928039\n",
      "================\n",
      "loss CE alpha 0.5738034818321467\n",
      "loss CE beta 0.9019699323922395\n",
      "================\n",
      "loss mse alpha 0.579414633847773\n",
      "loss mse beta 0.8400896272156387\n",
      "Step 5, Train Loss 3.5588, Val Loss 3.5883, Time 94.5s\n",
      "================\n",
      "loss BCE action 0.6585869086906314\n",
      "================\n",
      "loss CE alpha 0.5735263330861926\n",
      "loss CE beta 0.8826229022815824\n",
      "================\n",
      "loss mse alpha 0.5853988267248497\n",
      "loss mse beta 0.8350903089158237\n",
      "Step 6, Train Loss 3.5352, Val Loss 3.5674, Time 111.0s\n",
      "================\n",
      "loss BCE action 0.6550109723582864\n",
      "================\n",
      "loss CE alpha 0.5725558530539274\n",
      "loss CE beta 0.865163747780025\n",
      "================\n",
      "loss mse alpha 0.5786964458646253\n",
      "loss mse beta 0.8328069039154797\n",
      "Step 7, Train Loss 3.5042, Val Loss 3.5497, Time 126.3s\n",
      "================\n",
      "loss BCE action 0.6516770182177425\n",
      "================\n",
      "loss CE alpha 0.5727038394659758\n",
      "loss CE beta 0.853433896228671\n",
      "================\n",
      "loss mse alpha 0.5787196293938905\n",
      "loss mse beta 0.8310422555543482\n",
      "Step 8, Train Loss 3.4876, Val Loss 3.5312, Time 142.3s\n",
      "================\n",
      "loss BCE action 0.6490315170958638\n",
      "================\n",
      "loss CE alpha 0.572070281766355\n",
      "loss CE beta 0.8429447488859296\n",
      "================\n",
      "loss mse alpha 0.571845717774704\n",
      "loss mse beta 0.8285218519624322\n",
      "Step 9, Train Loss 3.4644, Val Loss 3.5463, Time 158.7s\n",
      "================\n",
      "loss BCE action 0.6467449849471449\n",
      "================\n",
      "loss CE alpha 0.5720415592193604\n",
      "loss CE beta 0.8322680508717895\n",
      "================\n",
      "loss mse alpha 0.5740258954232559\n",
      "loss mse beta 0.8301701439078897\n",
      "Step 10, Train Loss 3.4553, Val Loss 3.5065, Time 173.8s\n",
      "================\n",
      "loss BCE action 0.6448058066889644\n",
      "================\n",
      "loss CE alpha 0.5717749701812863\n",
      "loss CE beta 0.8265262616798281\n",
      "================\n",
      "loss mse alpha 0.5785927535267547\n",
      "loss mse beta 0.8296020524576306\n",
      "Step 11, Train Loss 3.4513, Val Loss 3.5098, Time 189.1s\n",
      "================\n",
      "loss BCE action 0.643020493723452\n",
      "================\n",
      "loss CE alpha 0.5721088474616408\n",
      "loss CE beta 0.8176011677831412\n",
      "================\n",
      "loss mse alpha 0.579632198694162\n",
      "loss mse beta 0.8279687804635614\n",
      "Step 12, Train Loss 3.4403, Val Loss 3.4855, Time 206.5s\n",
      "================\n",
      "loss BCE action 0.6413119707256556\n",
      "================\n",
      "loss CE alpha 0.5714538710191845\n",
      "loss CE beta 0.813405723683536\n",
      "================\n",
      "loss mse alpha 0.5721058349357918\n",
      "loss mse beta 0.8177842000965029\n",
      "Step 13, Train Loss 3.4161, Val Loss 3.4719, Time 227.2s\n",
      "================\n",
      "loss BCE action 0.6416123913601041\n",
      "================\n",
      "loss CE alpha 0.5708615966141224\n",
      "loss CE beta 0.7849792417138814\n",
      "================\n",
      "loss mse alpha 0.5744288333225995\n",
      "loss mse beta 0.809135846607387\n",
      "Step 14, Train Loss 3.3810, Val Loss 3.4272, Time 247.5s\n",
      "================\n",
      "loss BCE action 0.6392476698383689\n",
      "================\n",
      "loss CE alpha 0.57054955791682\n",
      "loss CE beta 0.7690416805446147\n",
      "================\n",
      "loss mse alpha 0.5711876734392718\n",
      "loss mse beta 0.7957173954695463\n",
      "Step 15, Train Loss 3.3457, Val Loss 3.4180, Time 266.0s\n",
      "================\n",
      "loss BCE action 0.6377464799210429\n",
      "================\n",
      "loss CE alpha 0.5702650059014559\n",
      "loss CE beta 0.7651338076218963\n",
      "================\n",
      "loss mse alpha 0.5730146882822738\n",
      "loss mse beta 0.781794628733769\n",
      "Step 16, Train Loss 3.3280, Val Loss 3.4208, Time 286.5s\n",
      "================\n",
      "loss BCE action 0.636570162884891\n",
      "================\n",
      "loss CE alpha 0.5698585908859968\n",
      "loss CE beta 0.7646668436005711\n",
      "================\n",
      "loss mse alpha 0.5703516943147406\n",
      "loss mse beta 0.7747501574922353\n",
      "Step 17, Train Loss 3.3162, Val Loss 3.3686, Time 306.2s\n",
      "================\n",
      "loss BCE action 0.6346711834892631\n",
      "================\n",
      "loss CE alpha 0.5690911693498493\n",
      "loss CE beta 0.7610903661698103\n",
      "================\n",
      "loss mse alpha 0.5675212230416946\n",
      "loss mse beta 0.7578722413629293\n",
      "Step 18, Train Loss 3.2902, Val Loss 3.3562, Time 326.7s\n",
      "================\n",
      "loss BCE action 0.6318623553961515\n",
      "================\n",
      "loss CE alpha 0.5684070135466754\n",
      "loss CE beta 0.7568025946617126\n",
      "================\n",
      "loss mse alpha 0.5640518194064498\n",
      "loss mse beta 0.7385590128134936\n",
      "Step 19, Train Loss 3.2597, Val Loss 3.3651, Time 346.6s\n",
      "================\n",
      "loss BCE action 0.6280969489365816\n",
      "================\n",
      "loss CE alpha 0.5677080850116909\n",
      "loss CE beta 0.7515936065465212\n",
      "================\n",
      "loss mse alpha 0.5702348739840091\n",
      "loss mse beta 0.7319477689452469\n",
      "Step 20, Train Loss 3.2496, Val Loss 3.3293, Time 366.8s\n",
      "================\n",
      "loss BCE action 0.6241742096841335\n",
      "================\n",
      "loss CE alpha 0.5672677922993898\n",
      "loss CE beta 0.7467987809330225\n",
      "================\n",
      "loss mse alpha 0.5688948361203074\n",
      "loss mse beta 0.723056553862989\n",
      "Step 21, Train Loss 3.2302, Val Loss 3.2985, Time 387.0s\n",
      "================\n",
      "loss BCE action 0.6207509571686387\n",
      "================\n",
      "loss CE alpha 0.5666005357168615\n",
      "loss CE beta 0.7431209236383438\n",
      "================\n",
      "loss mse alpha 0.5644882699707523\n",
      "loss mse beta 0.715293895965442\n",
      "Step 22, Train Loss 3.2103, Val Loss 3.3062, Time 407.4s\n",
      "================\n",
      "loss BCE action 0.6182860294356942\n",
      "================\n",
      "loss CE alpha 0.5659283357672393\n",
      "loss CE beta 0.7403376018628478\n",
      "================\n",
      "loss mse alpha 0.5674737906316295\n",
      "loss mse beta 0.7070835690014065\n",
      "Step 23, Train Loss 3.1991, Val Loss 3.2889, Time 428.1s\n",
      "================\n",
      "loss BCE action 0.6163334298878909\n",
      "================\n",
      "loss CE alpha 0.5662563408724963\n",
      "loss CE beta 0.7396502723917365\n",
      "================\n",
      "loss mse alpha 0.5641224462073297\n",
      "loss mse beta 0.7104872420197352\n",
      "Step 24, Train Loss 3.1968, Val Loss 3.2685, Time 447.5s\n",
      "================\n",
      "loss BCE action 0.6146597540006041\n",
      "================\n",
      "loss CE alpha 0.5657934729009867\n",
      "loss CE beta 0.7365932919085025\n",
      "================\n",
      "loss mse alpha 0.5613616078160704\n",
      "loss mse beta 0.6992466292344034\n",
      "Step 25, Train Loss 3.1777, Val Loss 3.2682, Time 467.8s\n",
      "================\n",
      "loss BCE action 0.6133780732750893\n",
      "================\n",
      "loss CE alpha 0.5652910629287362\n",
      "loss CE beta 0.7345116749405861\n",
      "================\n",
      "loss mse alpha 0.5631732800975442\n",
      "loss mse beta 0.6893331532133743\n",
      "Step 26, Train Loss 3.1657, Val Loss 3.3164, Time 487.9s\n",
      "================\n",
      "loss BCE action 0.6123489426448941\n",
      "================\n",
      "loss CE alpha 0.5658482742495835\n",
      "loss CE beta 0.7321114899590612\n",
      "================\n",
      "loss mse alpha 0.5651124741882085\n",
      "loss mse beta 0.6888425551820546\n",
      "Step 27, Train Loss 3.1643, Val Loss 3.2500, Time 508.5s\n",
      "================\n",
      "loss BCE action 0.6108242105692625\n",
      "================\n",
      "loss CE alpha 0.5649368040263653\n",
      "loss CE beta 0.7317806828767062\n",
      "================\n",
      "loss mse alpha 0.5607802948681637\n",
      "loss mse beta 0.6852468892466277\n",
      "Step 28, Train Loss 3.1536, Val Loss 3.2504, Time 528.3s\n",
      "================\n",
      "loss BCE action 0.6098335955291987\n",
      "================\n",
      "loss CE alpha 0.5646874475292861\n",
      "loss CE beta 0.729682776518166\n",
      "================\n",
      "loss mse alpha 0.5619898135075345\n",
      "loss mse beta 0.6807082928717136\n",
      "Step 29, Train Loss 3.1469, Val Loss 3.2498, Time 543.7s\n",
      "================\n",
      "loss BCE action 0.608502876572311\n",
      "================\n",
      "loss CE alpha 0.5643684431910515\n",
      "loss CE beta 0.7283092867583036\n",
      "================\n",
      "loss mse alpha 0.5589038667851127\n",
      "loss mse beta 0.6759819258004427\n",
      "Step 30, Train Loss 3.1361, Val Loss 3.2419, Time 559.0s\n",
      "================\n",
      "loss BCE action 0.6075908126309514\n",
      "================\n",
      "loss CE alpha 0.5640997088514268\n",
      "loss CE beta 0.7264112459495664\n",
      "================\n",
      "loss mse alpha 0.5602681673597545\n",
      "loss mse beta 0.6742797993589192\n",
      "Step 31, Train Loss 3.1326, Val Loss 3.2433, Time 574.4s\n",
      "================\n",
      "loss BCE action 0.6064395578578115\n",
      "================\n",
      "loss CE alpha 0.5637708561494946\n",
      "loss CE beta 0.7255650349892676\n",
      "================\n",
      "loss mse alpha 0.5572329523041845\n",
      "loss mse beta 0.6643577597569674\n",
      "Step 32, Train Loss 3.1174, Val Loss 3.2651, Time 589.9s\n",
      "================\n",
      "loss BCE action 0.6056012235581875\n",
      "================\n",
      "loss CE alpha 0.5638909510336816\n",
      "loss CE beta 0.7231219093315303\n",
      "================\n",
      "loss mse alpha 0.558961195894517\n",
      "loss mse beta 0.6612592705991119\n",
      "Step 33, Train Loss 3.1128, Val Loss 3.2427, Time 605.1s\n",
      "================\n",
      "loss BCE action 0.6047644257545471\n",
      "================\n",
      "loss CE alpha 0.5631494687870144\n",
      "loss CE beta 0.7222671099938452\n",
      "================\n",
      "loss mse alpha 0.5552326475968584\n",
      "loss mse beta 0.66061004078947\n",
      "Step 34, Train Loss 3.1060, Val Loss 3.2451, Time 620.2s\n",
      "================\n",
      "loss BCE action 0.6039833903312684\n",
      "================\n",
      "loss CE alpha 0.5632947303354741\n",
      "loss CE beta 0.7194959097541869\n",
      "================\n",
      "loss mse alpha 0.5553217618260533\n",
      "loss mse beta 0.6550330405589193\n",
      "Step 35, Train Loss 3.0971, Val Loss 3.2409, Time 635.4s\n",
      "================\n",
      "loss BCE action 0.6033127767965197\n",
      "================\n",
      "loss CE alpha 0.5630964180454612\n",
      "loss CE beta 0.7190023519098758\n",
      "================\n",
      "loss mse alpha 0.5548584894742816\n",
      "loss mse beta 0.6458379828836769\n",
      "Step 36, Train Loss 3.0861, Val Loss 3.2572, Time 650.5s\n",
      "================\n",
      "loss BCE action 0.6023761395364999\n",
      "================\n",
      "loss CE alpha 0.5628458797931671\n",
      "loss CE beta 0.717363628000021\n",
      "================\n",
      "loss mse alpha 0.5579438083106651\n",
      "loss mse beta 0.6395035950466991\n",
      "Step 37, Train Loss 3.0800, Val Loss 3.2277, Time 665.7s\n",
      "================\n",
      "loss BCE action 0.6016762301325798\n",
      "================\n",
      "loss CE alpha 0.5626184622757137\n",
      "loss CE beta 0.715321390889585\n",
      "================\n",
      "loss mse alpha 0.5524364470271393\n",
      "loss mse beta 0.6375911030452699\n",
      "Step 38, Train Loss 3.0696, Val Loss 3.2200, Time 681.0s\n",
      "================\n",
      "loss BCE action 0.6009189968928694\n",
      "================\n",
      "loss CE alpha 0.5626376648433506\n",
      "loss CE beta 0.7142376356758178\n",
      "================\n",
      "loss mse alpha 0.5531670331722125\n",
      "loss mse beta 0.6342651487328113\n",
      "Step 39, Train Loss 3.0652, Val Loss 3.2543, Time 696.1s\n",
      "================\n",
      "loss BCE action 0.600375110656023\n",
      "================\n",
      "loss CE alpha 0.5624663406051695\n",
      "loss CE beta 0.7126238692551852\n",
      "================\n",
      "loss mse alpha 0.5552256578113883\n",
      "loss mse beta 0.6280151646584272\n",
      "Step 40, Train Loss 3.0587, Val Loss 3.2415, Time 711.5s\n",
      "================\n",
      "loss BCE action 0.600062227062881\n",
      "================\n",
      "loss CE alpha 0.5622348935343325\n",
      "loss CE beta 0.679537907615304\n",
      "================\n",
      "loss mse alpha 0.5522219799458981\n",
      "loss mse beta 0.6237827858887612\n",
      "Step 41, Train Loss 3.0178, Val Loss 3.1821, Time 726.7s\n",
      "================\n",
      "loss BCE action 0.5994636232033372\n",
      "================\n",
      "loss CE alpha 0.5619802368804813\n",
      "loss CE beta 0.6698835287243128\n",
      "================\n",
      "loss mse alpha 0.5462015744764358\n",
      "loss mse beta 0.6186591453384608\n",
      "Step 42, Train Loss 2.9962, Val Loss 3.2445, Time 742.0s\n",
      "================\n",
      "loss BCE action 0.5990066152065993\n",
      "================\n",
      "loss CE alpha 0.5620134521275759\n",
      "loss CE beta 0.6679894872009754\n",
      "================\n",
      "loss mse alpha 0.5469973126892\n",
      "loss mse beta 0.6142059245146811\n",
      "Step 43, Train Loss 2.9902, Val Loss 3.2074, Time 757.1s\n",
      "================\n",
      "loss BCE action 0.5982320457696915\n",
      "================\n",
      "loss CE alpha 0.5617060638032854\n",
      "loss CE beta 0.6658392104320228\n",
      "================\n",
      "loss mse alpha 0.5415103969164192\n",
      "loss mse beta 0.6066943016368895\n",
      "Step 44, Train Loss 2.9740, Val Loss 3.2338, Time 772.3s\n",
      "================\n",
      "loss BCE action 0.5976501846686005\n",
      "================\n",
      "loss CE alpha 0.5615948018617928\n",
      "loss CE beta 0.6644108448177576\n",
      "================\n",
      "loss mse alpha 0.5460259532788768\n",
      "loss mse beta 0.602575917262584\n",
      "Step 45, Train Loss 2.9723, Val Loss 3.2163, Time 787.1s\n",
      "================\n",
      "loss BCE action 0.5969860645011067\n",
      "================\n",
      "loss CE alpha 0.5610202677547932\n",
      "loss CE beta 0.66287407791242\n",
      "================\n",
      "loss mse alpha 0.5406070504337549\n",
      "loss mse beta 0.5959023608826101\n",
      "Step 46, Train Loss 2.9574, Val Loss 3.2093, Time 802.0s\n",
      "================\n",
      "loss BCE action 0.5967038514092564\n",
      "================\n",
      "loss CE alpha 0.5610108614899219\n",
      "loss CE beta 0.6607047311961651\n",
      "================\n",
      "loss mse alpha 0.5395790931303054\n",
      "loss mse beta 0.5963571074418723\n",
      "Step 47, Train Loss 2.9544, Val Loss 3.2231, Time 817.1s\n",
      "================\n",
      "loss BCE action 0.596072244271636\n",
      "================\n",
      "loss CE alpha 0.5608406919054687\n",
      "loss CE beta 0.6595149671658873\n",
      "================\n",
      "loss mse alpha 0.538210837263614\n",
      "loss mse beta 0.5868791062850505\n",
      "Step 48, Train Loss 2.9415, Val Loss 3.1937, Time 832.1s\n",
      "================\n",
      "loss BCE action 0.595323683321476\n",
      "================\n",
      "loss CE alpha 0.5607280548661947\n",
      "loss CE beta 0.6563364122062921\n",
      "================\n",
      "loss mse alpha 0.537723627826199\n",
      "loss mse beta 0.5800340122543275\n",
      "Step 49, Train Loss 2.9301, Val Loss 3.2005, Time 847.2s\n",
      "================\n",
      "loss BCE action 0.5950538514181971\n",
      "================\n",
      "loss CE alpha 0.560544469486922\n",
      "loss CE beta 0.6543764435686171\n",
      "================\n",
      "loss mse alpha 0.536762231728062\n",
      "loss mse beta 0.5732062762137502\n",
      "Step 50, Train Loss 2.9199, Val Loss 3.2218, Time 862.5s\n",
      "================\n",
      "loss BCE action 0.5943991869688035\n",
      "================\n",
      "loss CE alpha 0.5604198352433741\n",
      "loss CE beta 0.653672437928617\n",
      "================\n",
      "loss mse alpha 0.5336944891372696\n",
      "loss mse beta 0.5674563719891011\n",
      "Step 51, Train Loss 2.9096, Val Loss 3.2240, Time 877.5s\n",
      "================\n",
      "loss BCE action 0.5941528586670757\n",
      "================\n",
      "loss CE alpha 0.5602586545050144\n",
      "loss CE beta 0.6516545553691685\n",
      "================\n",
      "loss mse alpha 0.5382814190816134\n",
      "loss mse beta 0.5612554176244885\n",
      "Step 52, Train Loss 2.9056, Val Loss 3.2183, Time 892.5s\n",
      "================\n",
      "loss BCE action 0.5937799685634673\n",
      "================\n",
      "loss CE alpha 0.5600052002817393\n",
      "loss CE beta 0.6491565364412963\n",
      "================\n",
      "loss mse alpha 0.5339018716942519\n",
      "loss mse beta 0.5589695426169783\n",
      "Step 53, Train Loss 2.8958, Val Loss 3.2080, Time 907.6s\n",
      "================\n",
      "loss BCE action 0.5932365475222469\n",
      "================\n",
      "loss CE alpha 0.5599187563173473\n",
      "loss CE beta 0.6491835804656148\n",
      "================\n",
      "loss mse alpha 0.5322327566333115\n",
      "loss mse beta 0.5564316146075725\n",
      "Step 54, Train Loss 2.8910, Val Loss 3.2229, Time 922.7s\n",
      "================\n",
      "loss BCE action 0.5929434975609184\n",
      "================\n",
      "loss CE alpha 0.5596342155709862\n",
      "loss CE beta 0.6473822725936771\n",
      "================\n",
      "loss mse alpha 0.5309538226108999\n",
      "loss mse beta 0.554820331861265\n",
      "Step 55, Train Loss 2.8857, Val Loss 3.2494, Time 938.0s\n",
      "================\n",
      "loss BCE action 0.5925421034917235\n",
      "================\n",
      "loss CE alpha 0.5594197919592261\n",
      "loss CE beta 0.6444367078132928\n",
      "================\n",
      "loss mse alpha 0.5248638967983424\n",
      "loss mse beta 0.5452373918611556\n",
      "Step 56, Train Loss 2.8665, Val Loss 3.2355, Time 953.2s\n",
      "================\n",
      "loss BCE action 0.5924062728881836\n",
      "================\n",
      "loss CE alpha 0.5589598971419036\n",
      "loss CE beta 0.6423431744799017\n",
      "================\n",
      "loss mse alpha 0.5230351791484281\n",
      "loss mse beta 0.5372712350450456\n",
      "Step 57, Train Loss 2.8540, Val Loss 3.2574, Time 968.4s\n",
      "================\n",
      "loss BCE action 0.5919330428354442\n",
      "================\n",
      "loss CE alpha 0.5593273215927184\n",
      "loss CE beta 0.642166752088815\n",
      "================\n",
      "loss mse alpha 0.5267647637054325\n",
      "loss mse beta 0.5340875701978802\n",
      "Step 58, Train Loss 2.8543, Val Loss 3.2675, Time 984.1s\n",
      "================\n",
      "loss BCE action 0.5915810560807586\n",
      "================\n",
      "loss CE alpha 0.5590341474860907\n",
      "loss CE beta 0.6390223435126245\n",
      "================\n",
      "loss mse alpha 0.5220370149938389\n",
      "loss mse beta 0.5274899936746806\n",
      "Step 59, Train Loss 2.8392, Val Loss 3.2805, Time 999.2s\n",
      "================\n",
      "loss BCE action 0.5910329969599843\n",
      "================\n",
      "loss CE alpha 0.5582037317566574\n",
      "loss CE beta 0.6386239366605878\n",
      "================\n",
      "loss mse alpha 0.517117143725045\n",
      "loss mse beta 0.5249701796099544\n",
      "Step 60, Train Loss 2.8299, Val Loss 3.2984, Time 1014.8s\n",
      "================\n",
      "loss BCE action 0.5907583653926849\n",
      "================\n",
      "loss CE alpha 0.557898008171469\n",
      "loss CE beta 0.6361842508427799\n",
      "================\n",
      "loss mse alpha 0.5175837851595133\n",
      "loss mse beta 0.521657615993172\n",
      "Step 61, Train Loss 2.8241, Val Loss 3.2546, Time 1030.3s\n",
      "================\n",
      "loss BCE action 0.5902507172897458\n",
      "================\n",
      "loss CE alpha 0.5577017554081977\n",
      "loss CE beta 0.6336449517868459\n",
      "================\n",
      "loss mse alpha 0.5151078448630869\n",
      "loss mse beta 0.5132535564247519\n",
      "Step 62, Train Loss 2.8100, Val Loss 3.2965, Time 1045.6s\n",
      "================\n",
      "loss BCE action 0.590077247004956\n",
      "================\n",
      "loss CE alpha 0.5573419535532593\n",
      "loss CE beta 0.6350699354894459\n",
      "================\n",
      "loss mse alpha 0.5107026234269142\n",
      "loss mse beta 0.5121023285668344\n",
      "Step 63, Train Loss 2.8053, Val Loss 3.2622, Time 1061.0s\n",
      "================\n",
      "loss BCE action 0.589403629116714\n",
      "================\n",
      "loss CE alpha 0.5573487205430865\n",
      "loss CE beta 0.6315412292256951\n",
      "================\n",
      "loss mse alpha 0.5140179046196863\n",
      "loss mse beta 0.511880309204571\n",
      "Step 64, Train Loss 2.8042, Val Loss 3.2645, Time 1077.3s\n",
      "================\n",
      "loss BCE action 0.5888519657775759\n",
      "================\n",
      "loss CE alpha 0.5567956901155412\n",
      "loss CE beta 0.629576101154089\n",
      "================\n",
      "loss mse alpha 0.5025514506502077\n",
      "loss mse beta 0.5012593872379512\n",
      "Step 65, Train Loss 2.7790, Val Loss 3.3388, Time 1093.1s\n",
      "================\n",
      "loss BCE action 0.5886883083730936\n",
      "================\n",
      "loss CE alpha 0.5564670831896364\n",
      "loss CE beta 0.6283639904111624\n",
      "================\n",
      "loss mse alpha 0.5069961990462616\n",
      "loss mse beta 0.4985872424673289\n",
      "Step 66, Train Loss 2.7791, Val Loss 3.2737, Time 1108.7s\n",
      "================\n",
      "loss BCE action 0.5882090284489095\n",
      "================\n",
      "loss CE alpha 0.5556914960034192\n",
      "loss CE beta 0.6250578120350838\n",
      "================\n",
      "loss mse alpha 0.4991721416125074\n",
      "loss mse beta 0.4940511045744643\n",
      "Step 67, Train Loss 2.7622, Val Loss 3.2922, Time 1123.9s\n",
      "================\n",
      "loss BCE action 0.5878935908898711\n",
      "================\n",
      "loss CE alpha 0.5557683045044541\n",
      "loss CE beta 0.624107847455889\n",
      "================\n",
      "loss mse alpha 0.4994769281940535\n",
      "loss mse beta 0.4886510751908645\n",
      "Step 68, Train Loss 2.7559, Val Loss 3.2797, Time 1138.8s\n",
      "================\n",
      "loss BCE action 0.5876809724606573\n",
      "================\n",
      "loss CE alpha 0.5556551015935838\n",
      "loss CE beta 0.6239473978057504\n",
      "================\n",
      "loss mse alpha 0.5019675008021295\n",
      "loss mse beta 0.49403323912993075\n",
      "Step 69, Train Loss 2.7633, Val Loss 3.3457, Time 1153.8s\n",
      "================\n",
      "loss BCE action 0.5868758788332343\n",
      "================\n",
      "loss CE alpha 0.5557124618440866\n",
      "loss CE beta 0.6207291851751506\n",
      "================\n",
      "loss mse alpha 0.49694984895177186\n",
      "loss mse beta 0.4803299432620406\n",
      "Step 70, Train Loss 2.7406, Val Loss 3.2981, Time 1168.8s\n",
      "================\n",
      "loss BCE action 0.5865921105258167\n",
      "================\n",
      "loss CE alpha 0.5550026922486723\n",
      "loss CE beta 0.6205718862824142\n",
      "================\n",
      "loss mse alpha 0.49510790093336254\n",
      "loss mse beta 0.4807738289469853\n",
      "Step 71, Train Loss 2.7380, Val Loss 3.2831, Time 1183.7s\n",
      "================\n",
      "loss BCE action 0.5861740487627685\n",
      "================\n",
      "loss CE alpha 0.553841779846698\n",
      "loss CE beta 0.6184533456340432\n",
      "================\n",
      "loss mse alpha 0.48594655266497283\n",
      "loss mse beta 0.47768627118784934\n",
      "Step 72, Train Loss 2.7221, Val Loss 3.3051, Time 1199.2s\n",
      "================\n",
      "loss BCE action 0.5859424233436584\n",
      "================\n",
      "loss CE alpha 0.5544644014909863\n",
      "loss CE beta 0.619787501078099\n",
      "================\n",
      "loss mse alpha 0.49038435861002655\n",
      "loss mse beta 0.48252902128733693\n",
      "Step 73, Train Loss 2.7331, Val Loss 3.3956, Time 1214.5s\n",
      "================\n",
      "loss BCE action 0.5850484925322235\n",
      "================\n",
      "loss CE alpha 0.5534391763620079\n",
      "loss CE beta 0.6153910502791404\n",
      "================\n",
      "loss mse alpha 0.48164542720187453\n",
      "loss mse beta 0.4712354037212208\n",
      "Step 74, Train Loss 2.7068, Val Loss 3.3336, Time 1230.0s\n",
      "================\n",
      "loss BCE action 0.5845046814531087\n",
      "================\n",
      "loss CE alpha 0.5528920823708177\n",
      "loss CE beta 0.6145851667039096\n",
      "================\n",
      "loss mse alpha 0.48154463423416016\n",
      "loss mse beta 0.46727589147631077\n",
      "Step 75, Train Loss 2.7008, Val Loss 3.3392, Time 1245.4s\n",
      "================\n",
      "loss BCE action 0.5841529586352407\n",
      "================\n",
      "loss CE alpha 0.5526862705126405\n",
      "loss CE beta 0.6128592742606997\n",
      "================\n",
      "loss mse alpha 0.4758230364881456\n",
      "loss mse beta 0.46748184573370966\n",
      "Step 76, Train Loss 2.6930, Val Loss 3.3816, Time 1261.4s\n",
      "================\n",
      "loss BCE action 0.5836866869591176\n",
      "================\n",
      "loss CE alpha 0.5525756929069757\n",
      "loss CE beta 0.6132055738009512\n",
      "================\n",
      "loss mse alpha 0.47924505012342705\n",
      "loss mse beta 0.4697200975148007\n",
      "Step 77, Train Loss 2.6984, Val Loss 3.3280, Time 1279.5s\n",
      "================\n",
      "loss BCE action 0.5831154562532902\n",
      "================\n",
      "loss CE alpha 0.5519550490193069\n",
      "loss CE beta 0.6111133610829711\n",
      "================\n",
      "loss mse alpha 0.47731676248367877\n",
      "loss mse beta 0.464409890701063\n",
      "Step 78, Train Loss 2.6879, Val Loss 3.3838, Time 1296.8s\n",
      "================\n",
      "loss BCE action 0.5825884267687798\n",
      "================\n",
      "loss CE alpha 0.5518922659568488\n",
      "loss CE beta 0.612483499571681\n",
      "================\n",
      "loss mse alpha 0.47579407659359274\n",
      "loss mse beta 0.4691720028873533\n",
      "Step 79, Train Loss 2.6919, Val Loss 3.2854, Time 1312.2s\n",
      "================\n",
      "loss BCE action 0.5818754469044507\n",
      "================\n",
      "loss CE alpha 0.5517206443473697\n",
      "loss CE beta 0.6117271496914327\n",
      "================\n",
      "loss mse alpha 0.47372423778288064\n",
      "loss mse beta 0.46733652385883034\n",
      "Step 80, Train Loss 2.6864, Val Loss 3.3534, Time 1328.9s\n",
      "================\n",
      "loss BCE action 0.581774518545717\n",
      "================\n",
      "loss CE alpha 0.5511263724416494\n",
      "loss CE beta 0.6066039381548762\n",
      "================\n",
      "loss mse alpha 0.4730697014601901\n",
      "loss mse beta 0.4538812942802906\n",
      "Step 81, Train Loss 2.6665, Val Loss 3.3572, Time 1345.2s\n",
      "================\n",
      "loss BCE action 0.5809172067791224\n",
      "================\n",
      "loss CE alpha 0.5504062251187861\n",
      "loss CE beta 0.6063950521871447\n",
      "================\n",
      "loss mse alpha 0.46723263934254644\n",
      "loss mse beta 0.4544165368191898\n",
      "Step 82, Train Loss 2.6594, Val Loss 3.3529, Time 1368.5s\n",
      "================\n",
      "loss BCE action 0.5805572306737303\n",
      "================\n",
      "loss CE alpha 0.5495172712020576\n",
      "loss CE beta 0.6058314962312579\n",
      "================\n",
      "loss mse alpha 0.4597312611993402\n",
      "loss mse beta 0.4509214010788128\n",
      "Step 83, Train Loss 2.6466, Val Loss 3.3567, Time 1384.0s\n",
      "================\n",
      "loss BCE action 0.5799688839353621\n",
      "================\n",
      "loss CE alpha 0.5490726567804813\n",
      "loss CE beta 0.6053250696510076\n",
      "================\n",
      "loss mse alpha 0.45735936050768944\n",
      "loss mse beta 0.452905071945861\n",
      "Step 84, Train Loss 2.6446, Val Loss 3.3392, Time 1399.4s\n",
      "================\n",
      "loss BCE action 0.5794764898717404\n",
      "================\n",
      "loss CE alpha 0.5489642602391541\n",
      "loss CE beta 0.6030935820192098\n",
      "================\n",
      "loss mse alpha 0.4560712050413713\n",
      "loss mse beta 0.4477771363919601\n",
      "Step 85, Train Loss 2.6354, Val Loss 3.3629, Time 1416.6s\n",
      "================\n",
      "loss BCE action 0.579384031612426\n",
      "================\n",
      "loss CE alpha 0.5487832992337645\n",
      "loss CE beta 0.6068314688280225\n",
      "================\n",
      "loss mse alpha 0.4575535484822467\n",
      "loss mse beta 0.46308343824930487\n",
      "Step 86, Train Loss 2.6556, Val Loss 3.3971, Time 1433.2s\n",
      "================\n",
      "loss BCE action 0.5788038632832467\n",
      "================\n",
      "loss CE alpha 0.5489232303574682\n",
      "loss CE beta 0.6043906087055803\n",
      "================\n",
      "loss mse alpha 0.457847246597521\n",
      "loss mse beta 0.4572087597567588\n",
      "Step 87, Train Loss 2.6472, Val Loss 3.4286, Time 1449.2s\n",
      "================\n",
      "loss BCE action 0.5780981197021902\n",
      "================\n",
      "loss CE alpha 0.5476140767335892\n",
      "loss CE beta 0.6000639973208308\n",
      "================\n",
      "loss mse alpha 0.44836456233169886\n",
      "loss mse beta 0.4392393880756572\n",
      "Step 88, Train Loss 2.6134, Val Loss 3.4302, Time 1465.1s\n",
      "================\n",
      "loss BCE action 0.5777012293227017\n",
      "================\n",
      "loss CE alpha 0.5468640018254518\n",
      "loss CE beta 0.5996804501861334\n",
      "================\n",
      "loss mse alpha 0.44502403037622573\n",
      "loss mse beta 0.4402660612249747\n",
      "Step 89, Train Loss 2.6095, Val Loss 3.3934, Time 1480.8s\n",
      "================\n",
      "loss BCE action 0.5771947160363198\n",
      "================\n",
      "loss CE alpha 0.5463936035521328\n",
      "loss CE beta 0.5994616437703371\n",
      "================\n",
      "loss mse alpha 0.4456163330003619\n",
      "loss mse beta 0.44201931010466067\n",
      "Step 90, Train Loss 2.6107, Val Loss 3.4441, Time 1497.1s\n",
      "================\n",
      "loss BCE action 0.5766358998604119\n",
      "================\n",
      "loss CE alpha 0.54671789733693\n",
      "loss CE beta 0.5972356716170907\n",
      "================\n",
      "loss mse alpha 0.4457281400449574\n",
      "loss mse beta 0.4373482663184404\n",
      "Step 91, Train Loss 2.6037, Val Loss 3.4230, Time 1513.3s\n",
      "================\n",
      "loss BCE action 0.5763539074920118\n",
      "================\n",
      "loss CE alpha 0.5456568606197834\n",
      "loss CE beta 0.5960260133258999\n",
      "================\n",
      "loss mse alpha 0.4433188742026687\n",
      "loss mse beta 0.43191848646383735\n",
      "Step 92, Train Loss 2.5933, Val Loss 3.3793, Time 1528.7s\n",
      "================\n",
      "loss BCE action 0.5759903729893268\n",
      "================\n",
      "loss CE alpha 0.5455916419625282\n",
      "loss CE beta 0.5951817944645882\n",
      "================\n",
      "loss mse alpha 0.4434485624777153\n",
      "loss mse beta 0.4316203043330461\n",
      "Step 93, Train Loss 2.5918, Val Loss 3.4423, Time 1544.5s\n",
      "================\n",
      "loss BCE action 0.5754362946376205\n",
      "================\n",
      "loss CE alpha 0.5446163592860103\n",
      "loss CE beta 0.595434614084661\n",
      "================\n",
      "loss mse alpha 0.4373860391089693\n",
      "loss mse beta 0.433230181154795\n",
      "Step 94, Train Loss 2.5861, Val Loss 3.4177, Time 1559.8s\n",
      "================\n",
      "loss BCE action 0.5749189869500697\n",
      "================\n",
      "loss CE alpha 0.5440672270953655\n",
      "loss CE beta 0.5930971872992814\n",
      "================\n",
      "loss mse alpha 0.43349507394013925\n",
      "loss mse beta 0.42819909867830575\n",
      "Step 95, Train Loss 2.5738, Val Loss 3.4259, Time 1574.7s\n",
      "================\n",
      "loss BCE action 0.5750574916601181\n",
      "================\n",
      "loss CE alpha 0.5441245313733816\n",
      "loss CE beta 0.5925574444234372\n",
      "================\n",
      "loss mse alpha 0.43438803965691475\n",
      "loss mse beta 0.42871084678918125\n",
      "Step 96, Train Loss 2.5748, Val Loss 3.4198, Time 1590.7s\n",
      "================\n",
      "loss BCE action 0.5748562187887728\n",
      "================\n",
      "loss CE alpha 0.5428349986672402\n",
      "loss CE beta 0.5948040868155658\n",
      "================\n",
      "loss mse alpha 0.43190054420847446\n",
      "loss mse beta 0.43228740328922866\n",
      "Step 97, Train Loss 2.5767, Val Loss 3.4808, Time 1606.5s\n",
      "================\n",
      "loss BCE action 0.5739121006801724\n",
      "================\n",
      "loss CE alpha 0.5435088062658906\n",
      "loss CE beta 0.5903304972685873\n",
      "================\n",
      "loss mse alpha 0.43593033354263755\n",
      "loss mse beta 0.4258143832907081\n",
      "Step 98, Train Loss 2.5695, Val Loss 3.4312, Time 1622.7s\n",
      "================\n",
      "loss BCE action 0.5737625322304666\n",
      "================\n",
      "loss CE alpha 0.5420501762069762\n",
      "loss CE beta 0.589323440566659\n",
      "================\n",
      "loss mse alpha 0.42553782584145666\n",
      "loss mse beta 0.4235637530684471\n",
      "Step 99, Train Loss 2.5542, Val Loss 3.4501, Time 1638.8s\n",
      "================\n",
      "loss BCE action 0.5731950199231506\n",
      "================\n",
      "loss CE alpha 0.5412793946452439\n",
      "loss CE beta 0.5887026032432914\n",
      "================\n",
      "loss mse alpha 0.4217798583908007\n",
      "loss mse beta 0.4220995843177661\n",
      "Step 100, Train Loss 2.5471, Val Loss 3.4398, Time 1655.1s\n",
      "================\n",
      "loss BCE action 0.5732256732881069\n",
      "================\n",
      "loss CE alpha 0.5415382795967162\n",
      "loss CE beta 0.5885948348790407\n",
      "================\n",
      "loss mse alpha 0.4300515995826572\n",
      "loss mse beta 0.42131640296429396\n",
      "Step 101, Train Loss 2.5547, Val Loss 3.4640, Time 1670.8s\n",
      "================\n",
      "loss BCE action 0.5726822233758867\n",
      "================\n",
      "loss CE alpha 0.5413410482928157\n",
      "loss CE beta 0.5890322244726122\n",
      "================\n",
      "loss mse alpha 0.4265593940857798\n",
      "loss mse beta 0.4239228059304878\n",
      "Step 102, Train Loss 2.5535, Val Loss 3.4664, Time 1686.8s\n",
      "================\n",
      "loss BCE action 0.5722825835458935\n",
      "================\n",
      "loss CE alpha 0.5400421420112252\n",
      "loss CE beta 0.5870140727609396\n",
      "================\n",
      "loss mse alpha 0.41905720841605215\n",
      "loss mse beta 0.41928436546586456\n",
      "Step 103, Train Loss 2.5377, Val Loss 3.4258, Time 1703.4s\n",
      "================\n",
      "loss BCE action 0.5718783269636333\n",
      "================\n",
      "loss CE alpha 0.5389581805095076\n",
      "loss CE beta 0.5847606776282191\n",
      "================\n",
      "loss mse alpha 0.4213147117057815\n",
      "loss mse beta 0.4203669790644199\n",
      "Step 104, Train Loss 2.5373, Val Loss 3.4844, Time 1719.1s\n",
      "================\n",
      "loss BCE action 0.5726322423666715\n",
      "================\n",
      "loss CE alpha 0.5410790903493762\n",
      "loss CE beta 0.5938930442556739\n",
      "================\n",
      "loss mse alpha 0.43362980380188676\n",
      "loss mse beta 0.4368745492538437\n",
      "Step 105, Train Loss 2.5781, Val Loss 3.4318, Time 1734.8s\n",
      "================\n",
      "loss BCE action 0.5714965164661407\n",
      "================\n",
      "loss CE alpha 0.5389898002147675\n",
      "loss CE beta 0.5818032095208764\n",
      "================\n",
      "loss mse alpha 0.4186384975211695\n",
      "loss mse beta 0.410301681375131\n",
      "Step 106, Train Loss 2.5212, Val Loss 3.4864, Time 1750.8s\n",
      "================\n",
      "loss BCE action 0.5715717622078955\n",
      "================\n",
      "loss CE alpha 0.5377803891897202\n",
      "loss CE beta 0.5803250058554112\n",
      "================\n",
      "loss mse alpha 0.4124704939313233\n",
      "loss mse beta 0.40858407635241745\n",
      "Step 107, Train Loss 2.5107, Val Loss 3.4949, Time 1766.6s\n",
      "================\n",
      "loss BCE action 0.5713358893059194\n",
      "================\n",
      "loss CE alpha 0.5380519038066268\n",
      "loss CE beta 0.5881673486903309\n",
      "================\n",
      "loss mse alpha 0.41653423036914317\n",
      "loss mse beta 0.42575393312145027\n",
      "Step 108, Train Loss 2.5398, Val Loss 3.4326, Time 1782.7s\n",
      "================\n",
      "loss BCE action 0.5705731126479805\n",
      "================\n",
      "loss CE alpha 0.537010333314538\n",
      "loss CE beta 0.5815352300181985\n",
      "================\n",
      "loss mse alpha 0.4144390411209315\n",
      "loss mse beta 0.4134449426084757\n",
      "Step 109, Train Loss 2.5170, Val Loss 3.4898, Time 1799.7s\n",
      "================\n",
      "loss BCE action 0.5705716360360384\n",
      "================\n",
      "loss CE alpha 0.5358581132255494\n",
      "loss CE beta 0.5779193702153862\n",
      "================\n",
      "loss mse alpha 0.40730494991876187\n",
      "loss mse beta 0.4042083241278306\n",
      "Step 110, Train Loss 2.4959, Val Loss 3.4807, Time 1816.5s\n",
      "================\n",
      "loss BCE action 0.5712220177985727\n",
      "================\n",
      "loss CE alpha 0.5391827256418764\n",
      "loss CE beta 0.5908511515706778\n",
      "================\n",
      "loss mse alpha 0.42762089117895813\n",
      "loss mse beta 0.43538316353224216\n",
      "Step 111, Train Loss 2.5643, Val Loss 3.4421, Time 1832.4s\n",
      "================\n",
      "loss BCE action 0.5699254377745092\n",
      "================\n",
      "loss CE alpha 0.5346789347939194\n",
      "loss CE beta 0.5790191586129367\n",
      "================\n",
      "loss mse alpha 0.4044913147808984\n",
      "loss mse beta 0.4082170341396704\n",
      "Step 112, Train Loss 2.4963, Val Loss 3.5005, Time 1848.3s\n",
      "================\n",
      "loss BCE action 0.5701268172822893\n",
      "================\n",
      "loss CE alpha 0.5357966657727957\n",
      "loss CE beta 0.5820620158687234\n",
      "================\n",
      "loss mse alpha 0.41210849517956377\n",
      "loss mse beta 0.4101550532504916\n",
      "Step 113, Train Loss 2.5102, Val Loss 3.4757, Time 1864.2s\n",
      "================\n",
      "loss BCE action 0.5695378702133894\n",
      "================\n",
      "loss CE alpha 0.5328825503587723\n",
      "loss CE beta 0.5746538404375314\n",
      "================\n",
      "loss mse alpha 0.3964466414647177\n",
      "loss mse beta 0.3980432278709486\n",
      "Step 114, Train Loss 2.4716, Val Loss 3.5103, Time 1880.8s\n",
      "================\n",
      "loss BCE action 0.5696182710118591\n",
      "================\n",
      "loss CE alpha 0.5330924436450004\n",
      "loss CE beta 0.5804214992560446\n",
      "================\n",
      "loss mse alpha 0.40588261091616007\n",
      "loss mse beta 0.41371625412721186\n",
      "Step 115, Train Loss 2.5027, Val Loss 3.4964, Time 1901.2s\n",
      "================\n",
      "loss BCE action 0.5697703439742327\n",
      "================\n",
      "loss CE alpha 0.5334015558473766\n",
      "loss CE beta 0.5768812951631844\n",
      "================\n",
      "loss mse alpha 0.4028403973439708\n",
      "loss mse beta 0.40476541088428347\n",
      "Step 116, Train Loss 2.4877, Val Loss 3.5105, Time 1922.1s\n",
      "================\n",
      "loss BCE action 0.5687913845293224\n",
      "================\n",
      "loss CE alpha 0.5323088381439447\n",
      "loss CE beta 0.5751132549718022\n",
      "================\n",
      "loss mse alpha 0.40001106755807997\n",
      "loss mse beta 0.40357149101328105\n",
      "Step 117, Train Loss 2.4798, Val Loss 3.5360, Time 1942.3s\n",
      "================\n",
      "loss BCE action 0.5687314064241946\n",
      "================\n",
      "loss CE alpha 0.5316426558420062\n",
      "loss CE beta 0.5741880445741117\n",
      "================\n",
      "loss mse alpha 0.39929521654266864\n",
      "loss mse beta 0.4031050404300913\n",
      "Step 118, Train Loss 2.4770, Val Loss 3.5077, Time 1961.6s\n",
      "================\n",
      "loss BCE action 0.5682872783392667\n",
      "================\n",
      "loss CE alpha 0.5305148239247501\n",
      "loss CE beta 0.5732409385964274\n",
      "================\n",
      "loss mse alpha 0.38891075195278973\n",
      "loss mse beta 0.3990483938716352\n",
      "Step 119, Train Loss 2.4600, Val Loss 3.5600, Time 1979.6s\n",
      "================\n",
      "loss BCE action 0.5686369601637125\n",
      "================\n",
      "loss CE alpha 0.5318418169394136\n",
      "loss CE beta 0.5753921455703676\n",
      "================\n",
      "loss mse alpha 0.3997696178499609\n",
      "loss mse beta 0.40449596918188035\n",
      "Step 120, Train Loss 2.4801, Val Loss 3.4970, Time 1997.7s\n",
      "================\n",
      "loss BCE action 0.5684270262718201\n",
      "================\n",
      "loss CE alpha 0.5304652948863804\n",
      "loss CE beta 0.5759092321619391\n",
      "================\n",
      "loss mse alpha 0.39426611000671985\n",
      "loss mse beta 0.4043314024573192\n",
      "Step 121, Train Loss 2.4734, Val Loss 3.5335, Time 2016.3s\n",
      "================\n",
      "loss BCE action 0.568266246560961\n",
      "================\n",
      "loss CE alpha 0.5287004391662776\n",
      "loss CE beta 0.5727925390005112\n",
      "================\n",
      "loss mse alpha 0.38948989124037325\n",
      "loss mse beta 0.39810206964612005\n",
      "Step 122, Train Loss 2.4574, Val Loss 3.5033, Time 2035.2s\n",
      "================\n",
      "loss BCE action 0.5678032508119941\n",
      "================\n",
      "loss CE alpha 0.5277507970109582\n",
      "loss CE beta 0.5707158213481307\n",
      "================\n",
      "loss mse alpha 0.38833625218831\n",
      "loss mse beta 0.3951393074821681\n",
      "Step 123, Train Loss 2.4497, Val Loss 3.5403, Time 2053.9s\n",
      "================\n",
      "loss BCE action 0.5679738780483603\n",
      "================\n",
      "loss CE alpha 0.5278146186843514\n",
      "loss CE beta 0.5697313838638365\n",
      "================\n",
      "loss mse alpha 0.38983472806867214\n",
      "loss mse beta 0.39588226224295797\n",
      "Step 124, Train Loss 2.4512, Val Loss 3.5485, Time 2072.4s\n",
      "================\n",
      "loss BCE action 0.5678096881136299\n",
      "================\n",
      "loss CE alpha 0.5276405001059175\n",
      "loss CE beta 0.5756809233687818\n",
      "================\n",
      "loss mse alpha 0.3918713390361518\n",
      "loss mse beta 0.40859751745592804\n",
      "Step 125, Train Loss 2.4716, Val Loss 3.5463, Time 2091.1s\n",
      "================\n",
      "loss BCE action 0.56743442453444\n",
      "================\n",
      "loss CE alpha 0.526693422999233\n",
      "loss CE beta 0.5717758105136455\n",
      "================\n",
      "loss mse alpha 0.3897889130515978\n",
      "loss mse beta 0.4000632307259366\n",
      "Step 126, Train Loss 2.4558, Val Loss 3.5428, Time 2109.2s\n",
      "================\n",
      "loss BCE action 0.5674510383978486\n",
      "================\n",
      "loss CE alpha 0.5255276817828417\n",
      "loss CE beta 0.5713061356917024\n",
      "================\n",
      "loss mse alpha 0.38508908518124374\n",
      "loss mse beta 0.400355848390609\n",
      "Step 127, Train Loss 2.4497, Val Loss 3.5830, Time 2126.9s\n",
      "================\n",
      "loss BCE action 0.5670969841070473\n",
      "================\n",
      "loss CE alpha 0.5235700040124357\n",
      "loss CE beta 0.5695098775438965\n",
      "================\n",
      "loss mse alpha 0.3815732717281207\n",
      "loss mse beta 0.39649840677157044\n",
      "Step 128, Train Loss 2.4382, Val Loss 3.5561, Time 2144.8s\n",
      "================\n",
      "loss BCE action 0.5667787966318428\n",
      "================\n",
      "loss CE alpha 0.5245795550756156\n",
      "loss CE beta 0.5703629812225699\n",
      "================\n",
      "loss mse alpha 0.38712776207830757\n",
      "loss mse beta 0.3981492965715006\n",
      "Step 129, Train Loss 2.4470, Val Loss 3.5312, Time 2163.2s\n",
      "================\n",
      "loss BCE action 0.5664867111481726\n",
      "================\n",
      "loss CE alpha 0.5219080379232764\n",
      "loss CE beta 0.5654883086681366\n",
      "================\n",
      "loss mse alpha 0.3763553761644289\n",
      "loss mse beta 0.38803977214265617\n",
      "Step 130, Train Loss 2.4183, Val Loss 3.5492, Time 2181.6s\n",
      "================\n",
      "loss BCE action 0.5668126918375492\n",
      "================\n",
      "loss CE alpha 0.5266977060586214\n",
      "loss CE beta 0.5771440859884024\n",
      "================\n",
      "loss mse alpha 0.4010757845127955\n",
      "loss mse beta 0.41483899208251385\n",
      "Step 131, Train Loss 2.4866, Val Loss 3.4584, Time 2200.6s\n",
      "================\n",
      "loss BCE action 0.5674845627509058\n",
      "================\n",
      "loss CE alpha 0.5305393792688846\n",
      "loss CE beta 0.5902368721552194\n",
      "================\n",
      "loss mse alpha 0.41790740529540926\n",
      "loss mse beta 0.4380798807134852\n",
      "Step 132, Train Loss 2.5442, Val Loss 3.3826, Time 2219.1s\n",
      "================\n",
      "loss BCE action 0.5664711810648442\n",
      "================\n",
      "loss CE alpha 0.5250058304518461\n",
      "loss CE beta 0.5737690139561892\n",
      "================\n",
      "loss mse alpha 0.3969533052993938\n",
      "loss mse beta 0.40716153890825807\n",
      "Step 133, Train Loss 2.4694, Val Loss 3.5034, Time 2237.8s\n",
      "================\n",
      "loss BCE action 0.5657224825583398\n",
      "================\n",
      "loss CE alpha 0.5205315499566495\n",
      "loss CE beta 0.5651737814769149\n",
      "================\n",
      "loss mse alpha 0.3774890806991607\n",
      "loss mse beta 0.38671491560526194\n",
      "Step 134, Train Loss 2.4156, Val Loss 3.5663, Time 2256.4s\n",
      "================\n",
      "loss BCE action 0.56590535659343\n",
      "================\n",
      "loss CE alpha 0.5196546679362655\n",
      "loss CE beta 0.5620956351980567\n",
      "================\n",
      "loss mse alpha 0.37673925126437097\n",
      "loss mse beta 0.3826115812873468\n",
      "Step 135, Train Loss 2.4070, Val Loss 3.5545, Time 2274.3s\n",
      "================\n",
      "loss BCE action 0.5652525859884918\n",
      "================\n",
      "loss CE alpha 0.5179611893370748\n",
      "loss CE beta 0.5609050729312003\n",
      "================\n",
      "loss mse alpha 0.37454063817858696\n",
      "loss mse beta 0.381264020409435\n",
      "Step 136, Train Loss 2.3999, Val Loss 3.5846, Time 2291.8s\n",
      "================\n",
      "loss BCE action 0.5653621289879084\n",
      "================\n",
      "loss CE alpha 0.5169588702730834\n",
      "loss CE beta 0.5624563463963568\n",
      "================\n",
      "loss mse alpha 0.37374568565282973\n",
      "loss mse beta 0.3849097742699087\n",
      "Step 137, Train Loss 2.4034, Val Loss 3.5607, Time 2309.8s\n",
      "================\n",
      "loss BCE action 0.5652147973887622\n",
      "================\n",
      "loss CE alpha 0.5169198116287589\n",
      "loss CE beta 0.5607791815884411\n",
      "================\n",
      "loss mse alpha 0.3747641931520775\n",
      "loss mse beta 0.381250314717181\n",
      "Step 138, Train Loss 2.3989, Val Loss 3.5979, Time 2328.6s\n",
      "================\n",
      "loss BCE action 0.5651151954196394\n",
      "================\n",
      "loss CE alpha 0.5172829712741077\n",
      "loss CE beta 0.5631649758666754\n",
      "================\n",
      "loss mse alpha 0.3801649150904268\n",
      "loss mse beta 0.38793480820022525\n",
      "Step 139, Train Loss 2.4137, Val Loss 3.5482, Time 2347.1s\n",
      "================\n",
      "loss BCE action 0.5655347181484103\n",
      "================\n",
      "loss CE alpha 0.5163787790574134\n",
      "loss CE beta 0.5653010643087327\n",
      "================\n",
      "loss mse alpha 0.3762549957260489\n",
      "loss mse beta 0.3885066563496366\n",
      "Step 140, Train Loss 2.4120, Val Loss 3.5527, Time 2365.8s\n",
      "================\n",
      "loss BCE action 0.565406141616404\n",
      "================\n",
      "loss CE alpha 0.5185504095628858\n",
      "loss CE beta 0.5717532090842724\n",
      "================\n",
      "loss mse alpha 0.38929203774314375\n",
      "loss mse beta 0.40598925643134864\n",
      "Step 141, Train Loss 2.4510, Val Loss 3.5400, Time 2384.5s\n",
      "================\n",
      "loss BCE action 0.5648284862749279\n",
      "================\n",
      "loss CE alpha 0.5139459548518062\n",
      "loss CE beta 0.5638519693166018\n",
      "================\n",
      "loss mse alpha 0.3702777147293091\n",
      "loss mse beta 0.3856845181668177\n",
      "Step 142, Train Loss 2.3986, Val Loss 3.6482, Time 2403.2s\n",
      "================\n",
      "loss BCE action 0.564784530736506\n",
      "================\n",
      "loss CE alpha 0.5114247418008745\n",
      "loss CE beta 0.5582148872315884\n",
      "================\n",
      "loss mse alpha 0.3623943388229236\n",
      "loss mse beta 0.3771269114455208\n",
      "Step 143, Train Loss 2.3739, Val Loss 3.5786, Time 2421.8s\n",
      "================\n",
      "loss BCE action 0.564832320716232\n",
      "================\n",
      "loss CE alpha 0.5139849080704153\n",
      "loss CE beta 0.5700832260772586\n",
      "================\n",
      "loss mse alpha 0.3799908483400941\n",
      "loss mse beta 0.4040142805315554\n",
      "Step 144, Train Loss 2.4329, Val Loss 3.6556, Time 2439.7s\n",
      "================\n",
      "loss BCE action 0.5675214103423059\n",
      "================\n",
      "loss CE alpha 0.5288614531978965\n",
      "loss CE beta 0.6222622156143188\n",
      "================\n",
      "loss mse alpha 0.437144816853106\n",
      "loss mse beta 0.5032826816895977\n",
      "Step 145, Train Loss 2.6591, Val Loss 3.4839, Time 2457.4s\n",
      "================\n",
      "loss BCE action 0.564784369058907\n",
      "================\n",
      "loss CE alpha 0.5133645265363157\n",
      "loss CE beta 0.5685214016586542\n",
      "================\n",
      "loss mse alpha 0.38251250206958504\n",
      "loss mse beta 0.39671887138392775\n",
      "Step 146, Train Loss 2.4259, Val Loss 3.5610, Time 2475.5s\n",
      "================\n",
      "loss BCE action 0.5642891289666295\n",
      "================\n",
      "loss CE alpha 0.5079221305437386\n",
      "loss CE beta 0.5593986229971051\n",
      "================\n",
      "loss mse alpha 0.3686109225731343\n",
      "loss mse beta 0.37967882710509004\n",
      "Step 147, Train Loss 2.3799, Val Loss 3.6204, Time 2493.9s\n",
      "================\n",
      "loss BCE action 0.5643162808381021\n",
      "================\n",
      "loss CE alpha 0.5041320726275444\n",
      "loss CE beta 0.5575542352162302\n",
      "================\n",
      "loss mse alpha 0.36342739812098446\n",
      "loss mse beta 0.3773881210479885\n",
      "Step 148, Train Loss 2.3668, Val Loss 3.5800, Time 2512.1s\n",
      "================\n",
      "loss BCE action 0.5641220923513174\n",
      "================\n",
      "loss CE alpha 0.5029903902672231\n",
      "loss CE beta 0.5569522978737951\n",
      "================\n",
      "loss mse alpha 0.36044969577342273\n",
      "loss mse beta 0.3765533519210294\n",
      "Step 149, Train Loss 2.3611, Val Loss 3.6845, Time 2530.9s\n",
      "================\n",
      "loss BCE action 0.563842573389411\n",
      "================\n",
      "loss CE alpha 0.5034834110178054\n",
      "loss CE beta 0.5597752961330116\n",
      "================\n",
      "loss mse alpha 0.3651598028372973\n",
      "loss mse beta 0.379292752686888\n",
      "Step 150, Train Loss 2.3716, Val Loss 3.6504, Time 2549.4s\n",
      "================\n",
      "loss BCE action 0.5637044115923345\n",
      "================\n",
      "loss CE alpha 0.49896964970976115\n",
      "loss CE beta 0.5548847985453904\n",
      "================\n",
      "loss mse alpha 0.3536949259461835\n",
      "loss mse beta 0.3736428902251646\n",
      "Step 151, Train Loss 2.3449, Val Loss 3.5982, Time 2567.9s\n",
      "================\n",
      "loss BCE action 0.5638754823245108\n",
      "================\n",
      "loss CE alpha 0.4983411647379398\n",
      "loss CE beta 0.5537161720916629\n",
      "================\n",
      "loss mse alpha 0.35485541832167655\n",
      "loss mse beta 0.3734636213630438\n",
      "Step 152, Train Loss 2.3443, Val Loss 3.6819, Time 2586.3s\n",
      "================\n",
      "loss BCE action 0.5635300104506313\n",
      "================\n",
      "loss CE alpha 0.49804734718054533\n",
      "loss CE beta 0.5591444034129381\n",
      "================\n",
      "loss mse alpha 0.35730551958549767\n",
      "loss mse beta 0.37862397062126546\n",
      "Step 153, Train Loss 2.3567, Val Loss 3.6080, Time 2604.5s\n",
      "================\n",
      "loss BCE action 0.5643449478782714\n",
      "================\n",
      "loss CE alpha 0.5087034715339541\n",
      "loss CE beta 0.5696022268384695\n",
      "================\n",
      "loss mse alpha 0.39527393588796256\n",
      "loss mse beta 0.40632776762358847\n",
      "Step 154, Train Loss 2.4443, Val Loss 3.5541, Time 2622.4s\n",
      "================\n",
      "loss BCE action 0.5635720210149884\n",
      "================\n",
      "loss CE alpha 0.5003061166964471\n",
      "loss CE beta 0.5602414675056935\n",
      "================\n",
      "loss mse alpha 0.37184910238720476\n",
      "loss mse beta 0.3881624444853514\n",
      "Step 155, Train Loss 2.3841, Val Loss 3.6311, Time 2640.4s\n",
      "================\n",
      "loss BCE action 0.5636237107217312\n",
      "================\n",
      "loss CE alpha 0.4971216223202646\n",
      "loss CE beta 0.5567872067913413\n",
      "================\n",
      "loss mse alpha 0.35963117212522777\n",
      "loss mse beta 0.3779030744219199\n",
      "Step 156, Train Loss 2.3551, Val Loss 3.6074, Time 2658.9s\n",
      "================\n",
      "loss BCE action 0.5631852963939309\n",
      "================\n",
      "loss CE alpha 0.4963931766338646\n",
      "loss CE beta 0.5569859394803643\n",
      "================\n",
      "loss mse alpha 0.35601076115854086\n",
      "loss mse beta 0.38009050029795616\n",
      "Step 157, Train Loss 2.3527, Val Loss 3.6327, Time 2677.6s\n",
      "================\n",
      "loss BCE action 0.5631865333765745\n",
      "================\n",
      "loss CE alpha 0.4966375375166535\n",
      "loss CE beta 0.5547464032657444\n",
      "================\n",
      "loss mse alpha 0.3595299051143229\n",
      "loss mse beta 0.37717590667307377\n",
      "Step 158, Train Loss 2.3513, Val Loss 3.6216, Time 2696.0s\n",
      "================\n",
      "loss BCE action 0.5625261857174337\n",
      "================\n",
      "loss CE alpha 0.49326081154868007\n",
      "loss CE beta 0.5508788266219199\n",
      "================\n",
      "loss mse alpha 0.34891422083601353\n",
      "loss mse beta 0.3685869881417602\n",
      "Step 159, Train Loss 2.3242, Val Loss 3.5846, Time 2714.4s\n",
      "================\n",
      "loss BCE action 0.5640346725471318\n",
      "================\n",
      "loss CE alpha 0.507081482000649\n",
      "loss CE beta 0.5785472211427987\n",
      "================\n",
      "loss mse alpha 0.39191973346751185\n",
      "loss mse beta 0.42140015559270977\n",
      "Step 160, Train Loss 2.4630, Val Loss 3.5572, Time 2732.7s\n",
      "================\n",
      "loss BCE action 0.563351285457611\n",
      "================\n",
      "loss CE alpha 0.5001224063336849\n",
      "loss CE beta 0.5695800769142807\n",
      "================\n",
      "loss mse alpha 0.37289945639204236\n",
      "loss mse beta 0.405988915450871\n",
      "Step 161, Train Loss 2.4119, Val Loss 3.5923, Time 2750.8s\n",
      "================\n",
      "loss BCE action 0.5627342294901609\n",
      "================\n",
      "loss CE alpha 0.4948498924262822\n",
      "loss CE beta 0.5570276602171361\n",
      "================\n",
      "loss mse alpha 0.3550106089795008\n",
      "loss mse beta 0.3809699831996113\n",
      "Step 162, Train Loss 2.3506, Val Loss 3.6352, Time 2768.8s\n",
      "================\n",
      "loss BCE action 0.5626084331423045\n",
      "================\n",
      "loss CE alpha 0.4937843058258295\n",
      "loss CE beta 0.5528987907804549\n",
      "================\n",
      "loss mse alpha 0.35411287476308645\n",
      "loss mse beta 0.37171939162071793\n",
      "Step 163, Train Loss 2.3351, Val Loss 3.6110, Time 2787.0s\n",
      "================\n",
      "loss BCE action 0.5619933709502221\n",
      "================\n",
      "loss CE alpha 0.4909698963165283\n",
      "loss CE beta 0.5517365610226989\n",
      "================\n",
      "loss mse alpha 0.3454634182853624\n",
      "loss mse beta 0.3681601146236062\n",
      "Step 164, Train Loss 2.3183, Val Loss 3.6201, Time 2805.2s\n",
      "================\n",
      "loss BCE action 0.56352226305753\n",
      "================\n",
      "loss CE alpha 0.5033956215716898\n",
      "loss CE beta 0.5772852331399918\n",
      "================\n",
      "loss mse alpha 0.38271595775149764\n",
      "loss mse beta 0.41869829872157427\n",
      "Step 165, Train Loss 2.4456, Val Loss 3.5903, Time 2823.6s\n",
      "================\n",
      "loss BCE action 0.5628397631458938\n",
      "================\n",
      "loss CE alpha 0.49921934511512517\n",
      "loss CE beta 0.5641825713217259\n",
      "================\n",
      "loss mse alpha 0.36995885947253554\n",
      "loss mse beta 0.39254636198747905\n",
      "Step 166, Train Loss 2.3887, Val Loss 3.6491, Time 2841.8s\n",
      "================\n",
      "loss BCE action 0.5627732533030212\n",
      "================\n",
      "loss CE alpha 0.4905520208179951\n",
      "loss CE beta 0.5541492734104395\n",
      "================\n",
      "loss mse alpha 0.3478749339701608\n",
      "loss mse beta 0.37154516237787905\n",
      "Step 167, Train Loss 2.3269, Val Loss 3.6952, Time 2860.2s\n",
      "================\n",
      "loss BCE action 0.5617476535961032\n",
      "================\n",
      "loss CE alpha 0.49152443474158647\n",
      "loss CE beta 0.553750716149807\n",
      "================\n",
      "loss mse alpha 0.35357348769903185\n",
      "loss mse beta 0.3721871102228761\n",
      "Step 168, Train Loss 2.3328, Val Loss 3.6254, Time 2878.1s\n",
      "================\n",
      "loss BCE action 0.5621148474514485\n",
      "================\n",
      "loss CE alpha 0.4933376407250762\n",
      "loss CE beta 0.5563278668560088\n",
      "================\n",
      "loss mse alpha 0.3609885547775775\n",
      "loss mse beta 0.38159036496654153\n",
      "Step 169, Train Loss 2.3544, Val Loss 3.6978, Time 2896.2s\n",
      "================\n",
      "loss BCE action 0.5621811270713806\n",
      "================\n",
      "loss CE alpha 0.4909237974323332\n",
      "loss CE beta 0.5570590583607554\n",
      "================\n",
      "loss mse alpha 0.35326310589443893\n",
      "loss mse beta 0.3814056530361995\n",
      "Step 170, Train Loss 2.3448, Val Loss 3.7077, Time 2914.6s\n",
      "================\n",
      "loss BCE action 0.5619569974020123\n",
      "================\n",
      "loss CE alpha 0.4909395842812955\n",
      "loss CE beta 0.5557330352254212\n",
      "================\n",
      "loss mse alpha 0.3532680372474715\n",
      "loss mse beta 0.3787933735875413\n",
      "Step 171, Train Loss 2.3407, Val Loss 3.6117, Time 2932.9s\n",
      "================\n",
      "loss BCE action 0.5615300374105573\n",
      "================\n",
      "loss CE alpha 0.4930954032577574\n",
      "loss CE beta 0.5561915225349366\n",
      "================\n",
      "loss mse alpha 0.3577136864187196\n",
      "loss mse beta 0.380300981993787\n",
      "Step 172, Train Loss 2.3488, Val Loss 3.6565, Time 2950.7s\n",
      "================\n",
      "loss BCE action 0.5618362442590297\n",
      "================\n",
      "loss CE alpha 0.4918107525445521\n",
      "loss CE beta 0.5552012490108609\n",
      "================\n",
      "loss mse alpha 0.3537425380549394\n",
      "loss mse beta 0.37429433963261544\n",
      "Step 173, Train Loss 2.3369, Val Loss 3.6415, Time 2968.9s\n",
      "================\n",
      "loss BCE action 0.5620704701170325\n",
      "================\n",
      "loss CE alpha 0.48908795043826103\n",
      "loss CE beta 0.5512122404761612\n",
      "================\n",
      "loss mse alpha 0.3470860240864567\n",
      "loss mse beta 0.3703559635207057\n",
      "Step 174, Train Loss 2.3198, Val Loss 3.7604, Time 2987.6s\n",
      "================\n",
      "loss BCE action 0.5613190304487944\n",
      "================\n",
      "loss CE alpha 0.495839468576014\n",
      "loss CE beta 0.5607060584239661\n",
      "================\n",
      "loss mse alpha 0.367433896381408\n",
      "loss mse beta 0.38787694291677327\n",
      "Step 175, Train Loss 2.3732, Val Loss 3.6852, Time 3006.2s\n",
      "================\n",
      "loss BCE action 0.5658809359185397\n",
      "================\n",
      "loss CE alpha 0.5314907352440059\n",
      "loss CE beta 0.6476990018971265\n",
      "================\n",
      "loss mse alpha 0.45525535312481225\n",
      "loss mse beta 0.5518491071881726\n",
      "Step 176, Train Loss 2.7522, Val Loss 3.6358, Time 3024.3s\n",
      "================\n",
      "loss BCE action 0.5624953065998852\n",
      "================\n",
      "loss CE alpha 0.5070715996436774\n",
      "loss CE beta 0.5838153119198978\n",
      "================\n",
      "loss mse alpha 0.4001652095466852\n",
      "loss mse beta 0.43532825987786056\n",
      "Step 177, Train Loss 2.4889, Val Loss 3.6127, Time 3042.5s\n",
      "================\n",
      "loss BCE action 0.5615672363899649\n",
      "================\n",
      "loss CE alpha 0.49526606053113936\n",
      "loss CE beta 0.5613856008276343\n",
      "================\n",
      "loss mse alpha 0.364352089795284\n",
      "loss mse beta 0.38808507290668787\n",
      "Step 178, Train Loss 2.3707, Val Loss 3.5957, Time 3060.8s\n",
      "================\n",
      "loss BCE action 0.5610447758808732\n",
      "================\n",
      "loss CE alpha 0.489674989040941\n",
      "loss CE beta 0.5529427575878799\n",
      "================\n",
      "loss mse alpha 0.34988566269166765\n",
      "loss mse beta 0.3724353906931356\n",
      "Step 179, Train Loss 2.3260, Val Loss 3.6590, Time 3079.2s\n",
      "================\n",
      "loss BCE action 0.5606823216192425\n",
      "================\n",
      "loss CE alpha 0.4870020471513271\n",
      "loss CE beta 0.5492667030543089\n",
      "================\n",
      "loss mse alpha 0.3437083006836474\n",
      "loss mse beta 0.36736041712574663\n",
      "Step 180, Train Loss 2.3080, Val Loss 3.6927, Time 3098.9s\n",
      "================\n",
      "loss BCE action 0.5607129677198828\n",
      "================\n",
      "loss CE alpha 0.48640091959387066\n",
      "loss CE beta 0.551104333717376\n",
      "================\n",
      "loss mse alpha 0.34550997053738686\n",
      "loss mse beta 0.3693555710371584\n",
      "Step 181, Train Loss 2.3131, Val Loss 3.6936, Time 3118.3s\n",
      "================\n",
      "loss BCE action 0.5606327287852764\n",
      "================\n",
      "loss CE alpha 0.4856627531349659\n",
      "loss CE beta 0.548278636019677\n",
      "================\n",
      "loss mse alpha 0.3418526519788429\n",
      "loss mse beta 0.36564247580245135\n",
      "Step 182, Train Loss 2.3021, Val Loss 3.7069, Time 3137.9s\n",
      "================\n",
      "loss BCE action 0.5605421944521367\n",
      "================\n",
      "loss CE alpha 0.48293309211730956\n",
      "loss CE beta 0.5445065694861114\n",
      "================\n",
      "loss mse alpha 0.33292362152133137\n",
      "loss mse beta 0.35834623938426374\n",
      "Step 183, Train Loss 2.2793, Val Loss 3.6606, Time 3157.9s\n",
      "================\n",
      "loss BCE action 0.5604979054071009\n",
      "================\n",
      "loss CE alpha 0.4827770796604455\n",
      "loss CE beta 0.545312138274312\n",
      "================\n",
      "loss mse alpha 0.33529974792618306\n",
      "loss mse beta 0.36083273927215487\n",
      "Step 184, Train Loss 2.2847, Val Loss 3.7266, Time 3177.8s\n",
      "================\n",
      "loss BCE action 0.5604251495562493\n",
      "================\n",
      "loss CE alpha 0.48366253040730955\n",
      "loss CE beta 0.546510637551546\n",
      "================\n",
      "loss mse alpha 0.336535385530442\n",
      "loss mse beta 0.3644324340624735\n",
      "Step 185, Train Loss 2.2916, Val Loss 3.7503, Time 3197.9s\n",
      "================\n",
      "loss BCE action 0.5604953628964722\n",
      "================\n",
      "loss CE alpha 0.48584588496014475\n",
      "loss CE beta 0.5546442928723991\n",
      "================\n",
      "loss mse alpha 0.34615816597361115\n",
      "loss mse beta 0.3804293085122481\n",
      "Step 186, Train Loss 2.3276, Val Loss 3.7027, Time 3217.6s\n",
      "================\n",
      "loss BCE action 0.5601693068630993\n",
      "================\n",
      "loss CE alpha 0.48512272592633965\n",
      "loss CE beta 0.5529820945113897\n",
      "================\n",
      "loss mse alpha 0.3439658892108127\n",
      "loss mse beta 0.3726031118072569\n",
      "Step 187, Train Loss 2.3148, Val Loss 3.7259, Time 3237.8s\n",
      "================\n",
      "loss BCE action 0.5606482456438243\n",
      "================\n",
      "loss CE alpha 0.4835977882146835\n",
      "loss CE beta 0.5443142796866596\n",
      "================\n",
      "loss mse alpha 0.3392790044192225\n",
      "loss mse beta 0.35952535457909107\n",
      "Step 188, Train Loss 2.2874, Val Loss 3.7379, Time 3257.9s\n",
      "================\n",
      "loss BCE action 0.5614666168577969\n",
      "================\n",
      "loss CE alpha 0.4900273255072534\n",
      "loss CE beta 0.5655236340127885\n",
      "================\n",
      "loss mse alpha 0.35833438492845743\n",
      "loss mse beta 0.39878216879442335\n",
      "Step 189, Train Loss 2.3741, Val Loss 3.5698, Time 3277.8s\n",
      "================\n",
      "loss BCE action 0.5612393544986845\n",
      "================\n",
      "loss CE alpha 0.49588908683508637\n",
      "loss CE beta 0.5677640005014837\n",
      "================\n",
      "loss mse alpha 0.371230236091651\n",
      "loss mse beta 0.40445361682213843\n",
      "Step 190, Train Loss 2.4006, Val Loss 3.7644, Time 3296.9s\n",
      "================\n",
      "loss BCE action 0.5602088178507983\n",
      "================\n",
      "loss CE alpha 0.48328169183805586\n",
      "loss CE beta 0.5463659494183958\n",
      "================\n",
      "loss mse alpha 0.33759907181374726\n",
      "loss mse beta 0.3626288930652663\n",
      "Step 191, Train Loss 2.2901, Val Loss 3.7900, Time 3316.6s\n",
      "================\n",
      "loss BCE action 0.5595328520052135\n",
      "================\n",
      "loss CE alpha 0.48150025606155394\n",
      "loss CE beta 0.5441026091575623\n",
      "================\n",
      "loss mse alpha 0.3338385736104101\n",
      "loss mse beta 0.36031484729610386\n",
      "Step 192, Train Loss 2.2793, Val Loss 3.7623, Time 3335.7s\n",
      "================\n",
      "loss BCE action 0.5602034620940686\n",
      "================\n",
      "loss CE alpha 0.4853739530779421\n",
      "loss CE beta 0.5465975281782448\n",
      "================\n",
      "loss mse alpha 0.3449279570719227\n",
      "loss mse beta 0.36846526092849674\n",
      "Step 193, Train Loss 2.3056, Val Loss 3.7212, Time 3355.3s\n",
      "================\n",
      "loss BCE action 0.56050632186234\n",
      "================\n",
      "loss CE alpha 0.4897924143821001\n",
      "loss CE beta 0.5560394923202694\n",
      "================\n",
      "loss mse alpha 0.3552969014737755\n",
      "loss mse beta 0.3812619199510664\n",
      "Step 194, Train Loss 2.3429, Val Loss 3.6624, Time 3374.7s\n",
      "================\n",
      "loss BCE action 0.5596840681508184\n",
      "================\n",
      "loss CE alpha 0.48400164460763334\n",
      "loss CE beta 0.5467103147879243\n",
      "================\n",
      "loss mse alpha 0.33825266011990607\n",
      "loss mse beta 0.3657412609085441\n",
      "Step 195, Train Loss 2.2944, Val Loss 3.7324, Time 3394.8s\n",
      "================\n",
      "loss BCE action 0.5595473145134747\n",
      "================\n",
      "loss CE alpha 0.4825152810662985\n",
      "loss CE beta 0.5452864049933851\n",
      "================\n",
      "loss mse alpha 0.33669013837352396\n",
      "loss mse beta 0.36485421541146934\n",
      "Step 196, Train Loss 2.2889, Val Loss 3.7415, Time 3414.0s\n",
      "================\n",
      "loss BCE action 0.559069715347141\n",
      "================\n",
      "loss CE alpha 0.480203010328114\n",
      "loss CE beta 0.5412632202729583\n",
      "================\n",
      "loss mse alpha 0.3302338822744787\n",
      "loss mse beta 0.3539481316227466\n",
      "Step 197, Train Loss 2.2647, Val Loss 3.7700, Time 3435.9s\n",
      "================\n",
      "loss BCE action 0.5597494478337467\n",
      "================\n",
      "loss CE alpha 0.48121567759662864\n",
      "loss CE beta 0.5443704191595315\n",
      "================\n",
      "loss mse alpha 0.33700866310391575\n",
      "loss mse beta 0.36352707389742134\n",
      "Step 198, Train Loss 2.2859, Val Loss 3.8348, Time 3456.8s\n",
      "================\n",
      "loss BCE action 0.5602278934791685\n",
      "================\n",
      "loss CE alpha 0.48357231356203556\n",
      "loss CE beta 0.5482890154235065\n",
      "================\n",
      "loss mse alpha 0.34238893394358455\n",
      "loss mse beta 0.37061839252710344\n",
      "Step 199, Train Loss 2.3051, Val Loss 3.7147, Time 3478.2s\n",
      "================\n",
      "loss BCE action 0.5592261549085379\n",
      "================\n",
      "loss CE alpha 0.47979354318231343\n",
      "loss CE beta 0.5445471023209393\n",
      "================\n",
      "loss mse alpha 0.33338615447282793\n",
      "loss mse beta 0.36247554172296076\n",
      "Step 200, Train Loss 2.2794, Val Loss 3.7559, Time 3500.3s\n"
     ]
    }
   ],
   "source": [
    "aBatch = 1000\n",
    "aHidden = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset,shuffle=False,batch_size=aBatch)\n",
    "val_loader = DataLoader(val_dataset,shuffle=False,batch_size=aBatch)\n",
    "rnn = GRU_RNN_TWO(\n",
    "              input_size=INPUT_SIZE,\n",
    "              hidden_size=aHidden,\n",
    "              num_of_layers=1,\n",
    "              num_alpha_embedding=num_alpha_embedding,\n",
    "              num_beta_embedding=num_beta_embedding,\n",
    "              output_size=OUTPUT_SIZE,\n",
    "              dropout=0.2\n",
    "             ) \n",
    "\n",
    "rnn, loss_train, loss_val = train_model_two(rnn, train_loader, val_loader, 200, 9) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
